{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "main_colab_CNN_co-teaching.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hiya906/my-machine-learning/blob/master/movie_review_LSTM_CNN_co_teaching.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGL8ad1gWyoi",
        "colab_type": "text"
      },
      "source": [
        "# SDS NLP Challenge\n",
        "\n",
        "- 이 Challenge는 자연어 처리를 통해 영화 감상평을 보고 영화 평점을 예측하는 것을 목적으로 합니다.\n",
        "- 데이터는 2 종류가 있습니다: IMDB (영어), NSMC (한국어)\n",
        "- 전처리, 학습 및 평가 템플릿은 아래와 같이 제공됩니다. 원하시는 대로 Parameter를 조절하고 'MyModel'에 해당하는 본인의 모델을 구현하여 실험하시면 됩니다.\n",
        "- Baseline 성능은 XXX와 같습니다.\n",
        "- Challenge 설명 PPT에 더 자세한 설명이 들어있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VyuvW4lWyoj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.mkdir('data')\n",
        "os.mkdir('models')\n",
        "os.mkdir('util')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-50Pfhsolgc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "698e5d67-cfe2-4d3b-9a60-b160c2f195be"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "print(dir(tf.feature_column))\n",
        "# !pip install tensorflow==1.4.0"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.4.0\n",
            "['__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', '_allowed_symbols', 'bucketized_column', 'categorical_column_with_hash_bucket', 'categorical_column_with_identity', 'categorical_column_with_vocabulary_file', 'categorical_column_with_vocabulary_list', 'crossed_column', 'embedding_column', 'indicator_column', 'input_layer', 'linear_model', 'make_parse_example_spec', 'numeric_column', 'weighted_categorical_column']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2yGa2OVWyom",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# IMPORT PACKAGE\n",
        "import time\n",
        "import argparse\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from util.Data_loader import load_data\n",
        "from util.Dataset import Dataset\n",
        "from util.Parser import vocab_dictionary, parse_data\n",
        "\n",
        "from models.Baseline_LSTM import LSTM\n",
        "from models.Baseline_Char_CNN import Char_CNN"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqmHdk-WWyop",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# imdb, nsmc\n",
        "DATA_NAME = 'imdb'\n",
        "\n",
        "# 전처리 방법\n",
        "# imdb (영어) = word \n",
        "# nsmc (한글) = eumjeol or char (음절 or 음소)\n",
        "PARSER = 'word'\n",
        "\n",
        "MAXLEN = 300\n",
        "# BATCH_SIZE = 256\n",
        "# LEARNING_RATE = 0.01\n",
        "BATCH_SIZE = 256\n",
        "LEARNING_RATE = 0.01"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lwXXrmpWyoq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_file = DATA_NAME + '_train.txt'\n",
        "test_file = DATA_NAME + '_test.txt'\n",
        "train_comments, train_ratings, test_comments, test_ratings = load_data('data', train_file, test_file)\n",
        "\n",
        "str2idx = vocab_dictionary(train_comments, PARSER)\n",
        "idx2str = {i: s for s, i in str2idx.items()}\n",
        "\n",
        "CHARSIZE = len(str2idx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88vFaON3Wyos",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 전처리\n",
        "train_x = parse_data(train_comments, str2idx, PARSER)\n",
        "train_y = train_ratings\n",
        "\n",
        "test_x = parse_data(test_comments, str2idx, PARSER)\n",
        "test_y = test_ratings"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vz_rwAMCWyot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 데이터셋\n",
        "train_dataset = Dataset(train_x, train_y, MAXLEN, BATCH_SIZE, shuffle=True)\n",
        "test_dataset = Dataset(test_x, test_y, MAXLEN, BATCH_SIZE, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AS4GaIuXybzX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class My_LSTM():\n",
        "    def __init__(self, x, y, in_len, embedding, rnn_hidden, bi, fc_layers, maxlen, char_size, lr):\n",
        "        self.embedding = embedding\n",
        "        self.rnn_hidden = rnn_hidden\n",
        "        self.bi = bi\n",
        "        self.fc_layers = fc_layers\n",
        "        self.input_len = maxlen\n",
        "        self.char_size = char_size\n",
        "        self.lr = lr\n",
        "        self.squered_error = None\n",
        "\n",
        "        with tf.name_scope(\"Input-Layer\"):\n",
        "            # Input\n",
        "#             self.x = tf.placeholder(tf.int64, shape=[None, self.input_len], name=\"input_x\")\n",
        "#             self.y = tf.placeholder(tf.float32, shape=[None], name=\"output_y\")\n",
        "            self.x = x\n",
        "            self.y = y\n",
        "#             self.x_len = tf.placeholder(tf.int64, shape=[None], name=\"input_len\")\n",
        "            self.x_len = in_len\n",
        "\n",
        "            embedding_matrix = tf.Variable(tf.random_normal([self.char_size, self.embedding], stddev=0.01),\n",
        "                                           name='Embedding_matrix')\n",
        "\n",
        "        # EMBEDDING LAYERS\n",
        "        with tf.name_scope(\"Embedding-Layer\"):\n",
        "            # CNN (tf.conv2d) : input = [batch, in_height, in_width, in_channels]\n",
        "            # NLP embedding only has 1 channels\n",
        "            # shape = (Batch, input_len, Embedding, 1)\n",
        "            x_emb = tf.nn.embedding_lookup(embedding_matrix, self.x)\n",
        "\n",
        "        input_shape = tf.shape(x_emb)\n",
        "\n",
        "        # LSTM Layer\n",
        "        with tf.name_scope('RNN-Layer'):\n",
        "            cell = tf.nn.rnn_cell.BasicLSTMCell(num_units=self.rnn_hidden)\n",
        "            init_state_fw = cell.zero_state(batch_size=input_shape[0], dtype=tf.float32)\n",
        "            if self.bi:\n",
        "                cell2 = tf.nn.rnn_cell.BasicLSTMCell(num_units=self.rnn_hidden)\n",
        "                init_state_bw = cell.zero_state(batch_size=input_shape[0], dtype=tf.float32)\n",
        "\n",
        "                output, final_state = tf.nn.bidirectional_dynamic_rnn(cell, cell2, x_emb,\n",
        "                                                                      initial_state_fw=init_state_fw,\n",
        "                                                                      initial_state_bw=init_state_bw, time_major=False,\n",
        "                                                                      sequence_length=self.x_len)\n",
        "                h = tf.concat([final_state[0].h, final_state[1].h], 1)\n",
        "                output = tf.concat(output, 2)\n",
        "            else:\n",
        "                output, final_state = tf.nn.dynamic_rnn(cell, x_emb, initial_state=init_state_fw, time_major=False,\n",
        "                                                        sequence_length=self.x_len)\n",
        "                h = final_state.h\n",
        "\n",
        "            output_shape = output.get_shape()\n",
        "\n",
        "            d = output_shape[-1].value\n",
        "\n",
        "            # 1. Use Last Hidden Only  (Batch x Hidden)\n",
        "            # rnn_output = h\n",
        "\n",
        "            # 2. Use Mean Pooling      (Batch x Hidden)\n",
        "            rnn_output = tf.reduce_mean(output, axis=1)\n",
        "\n",
        "            # 3. Use All Hidden      (Batch x d)\n",
        "            # d = output_shape[1].value * output_shape[2].value\n",
        "            # rnn_output = tf.reshape(output, [-1, d])\n",
        "\n",
        "        fc_input = rnn_output\n",
        "        for i, fc_dim in enumerate(self.fc_layers):\n",
        "            with tf.name_scope(\"FC-Layer-\" + str(i)):\n",
        "                W = tf.Variable(tf.random_normal([d, fc_dim], stddev=0.01), name=\"FC_W\" + str(i))\n",
        "                b = tf.Variable(tf.random_normal([fc_dim], stddev=0.01), name=\"FC_b\" + str(i))\n",
        "\n",
        "                fc_input = tf.nn.xw_plus_b(fc_input, W, b, name=\"FC\" + str(i))\n",
        "                fc_input = tf.nn.dropout(tf.nn.relu(fc_input), 0.5)\n",
        "                d = fc_dim\n",
        "\n",
        "        fc_output = fc_input\n",
        "\n",
        "        with tf.name_scope(\"Output-Layer\"):\n",
        "\n",
        "            W = tf.Variable(tf.random_normal([d, 1], stddev=0.01), name=\"Output_W\")\n",
        "            b = tf.Variable(tf.random_normal([1], stddev=0.01), name=\"Output_b\")\n",
        "\n",
        "            output = tf.squeeze(tf.matmul(fc_output, W) + b, 1)\n",
        "            self.pred = output\n",
        "\n",
        "        with tf.name_scope(\"Loss\"):\n",
        "            self.squared_error = tf.square(self.y - output)\n",
        "            self.loss = tf.reduce_mean(self.squared_error)\n",
        "\n",
        "        optimizer = tf.train.AdamOptimizer(learning_rate=self.lr)\n",
        "        self.train_step = optimizer.minimize(self.loss)\n",
        "\n",
        "    def __str__(self):\n",
        "        name = \"LSTM\"\n",
        "        bi = \"Bidirectional : \" + str(self.bi)\n",
        "        embeddings = \"Embedding Size : \" + str(self.embedding)\n",
        "        hidden = \"RNN HIDDEN : \" + str(self.rnn_hidden)\n",
        "        layers = \"FC Layers : \" + str(self.fc_layers)\n",
        "\n",
        "        return '\\n'.join([name, bi, embeddings, hidden, layers])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yy0f9wLRiunG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "class MyModel_CNN():\n",
        "    def __init__(self, x, y, embedding, conv_layers, fc_layers, maxlen, char_size, lr):\n",
        "        self.embedding = embedding\n",
        "        self.input_len = maxlen\n",
        "        self.char_size = char_size\n",
        "        self.conv_layers = conv_layers\n",
        "        self.fc_layers = fc_layers\n",
        "        self.lr = lr\n",
        "        self.squared_error = None\n",
        "        \n",
        "#         self.output_keep_prob = tf.placeholder(tf.float32, name='output_keep_prob')\n",
        "\n",
        "        with tf.name_scope(\"Input-Layer\"):\n",
        "            # Input\n",
        "#             self.x = tf.placeholder(tf.int64, shape=[None, self.input_len], name=\"input_x\")\n",
        "#             self.y = tf.placeholder(tf.float32, shape=[None], name=\"output_y\")\n",
        "            self.x = x\n",
        "            self.y = y\n",
        "            embedding_matrix = tf.Variable(tf.random_normal([self.char_size, self.embedding], stddev=0.01), name='Embedding_matrix')\n",
        "            print(\"Embedding Matrix: \", embedding_matrix.shape)\n",
        "\n",
        "        # EMBEDDING LAYERS\n",
        "        with tf.name_scope(\"Embedding-Layer\"):\n",
        "            cnn_x = tf.nn.embedding_lookup(embedding_matrix, self.x)\n",
        "            cnn_x = tf.expand_dims(cnn_x, -1)\n",
        "        \n",
        "        \n",
        "        # ================================ Version 2 =================================\n",
        "        # CONVOLUTION LAYERS\n",
        "        for i, conv_info in enumerate(self.conv_layers):\n",
        "            print(\"CNN Input: \", cnn_x.shape)\n",
        "            with tf.name_scope(\"Conv-Layer\" + str(i)):\n",
        "                filter_width = cnn_x.get_shape()[2].value\n",
        "                filter_shape = [conv_info[1], filter_width, 1, conv_info[0]]\n",
        "\n",
        "                W = tf.Variable(tf.random_normal(filter_shape,  mean=0.0, stddev=0.01), dtype=tf.float32,\n",
        "                                name='Conv_W')  # large = 0.02 , small = 0.05\n",
        "                b = tf.Variable(tf.random_normal(shape=[conv_info[0]],  mean=0.0, stddev=0.01), dtype=tf.float32,\n",
        "                                name='Conv_b')\n",
        "\n",
        "                conv = tf.nn.conv2d(cnn_x, W, [1, 1, 1, 1], \"VALID\", name=\"conv\")\n",
        "                cnn_x = tf.nn.bias_add(conv, b)\n",
        "\n",
        "            with tf.name_scope(\"Non-Linear\"):\n",
        "                cnn_x = tf.nn.relu(cnn_x)\n",
        "#                 cnn_x = tf.nn.tanh(cnn_x)\n",
        "            print(\"CNN Output: \", cnn_x.shape)\n",
        "            if conv_info[-1] != -1:\n",
        "                print(\"Pooling Input: \", cnn_x.shape)\n",
        "                with tf.name_scope(\"Max-Polling\"):\n",
        "                    pool_shape = [1, conv_info[-1], 1, 1]\n",
        "                    pool = tf.nn.max_pool(cnn_x, ksize=pool_shape, strides=pool_shape, padding=\"VALID\")\n",
        "                    cnn_x = tf.transpose(pool, [0, 1, 3, 2])\n",
        "                print(\"Pooling Output: \", cnn_x.shape)\n",
        "            else:\n",
        "                cnn_x = tf.transpose(cnn_x, [0, 1, 3, 2])\n",
        "        cnn_output = tf.squeeze(cnn_x, axis=3)\n",
        "\n",
        "        # Flatten cnn_output: (batch, height, width)  --> (batch, height * width)\n",
        "        out_shape = cnn_output.get_shape()\n",
        "        d = out_shape[1].value * out_shape[2].value\n",
        "        print('out_shape[1].value: ', out_shape[1].value)\n",
        "        print('out_shape[2].value: ', out_shape[2].value)\n",
        "        fc_input = tf.reshape(cnn_output, [-1, d])\n",
        "        print('fc_input: ', fc_input)\n",
        "\n",
        "        # Add dropout\n",
        "#         keep_prob = tf.placeholder(tf.float32)\n",
        "#         h_drop = tf.nn.dropout(fc_input, self.output_keep_prob)\n",
        "        \n",
        "        # Regression layer\n",
        "        print(\"Output Layer input: \", fc_input.shape)\n",
        "        with tf.name_scope(\"Output-Layer\"):\n",
        "            W = tf.Variable(tf.random_normal([d, 1], stddev=0.01), name=\"Output_W\")\n",
        "            b = tf.Variable(tf.random_normal([1], stddev=0.01), name=\"Output_b\")\n",
        "\n",
        "            output = tf.squeeze(tf.matmul(fc_input, W) + b, 1)\n",
        "            self.pred = output\n",
        "        print(\"Output Layer output: \", output.shape)\n",
        "\n",
        "        with tf.name_scope(\"Loss\"):\n",
        "            self.squared_error = tf.square(self.y - output)\n",
        "            self.loss = tf.reduce_mean(self.squared_error)\n",
        "\n",
        "        optimizer = tf.train.AdamOptimizer(learning_rate=self.lr)\n",
        "        self.train_step = optimizer.minimize(self.loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iw-9Yqv9xfNw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQlAiqPOWyov",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyModel:\n",
        "    def __init__(self, embedding, conv_layers, fc_layers, maxlen, char_size, lr):\n",
        "        # Input Placeholders\n",
        "        self.embedding = embedding\n",
        "        self.input_len = maxlen\n",
        "        self.char_size = char_size\n",
        "        self.conv_layers = conv_layers\n",
        "        self.fc_layers = fc_layers\n",
        "        self.lr = lr   \n",
        "                 \n",
        "        self.x = tf.placeholder(tf.int64, shape=[None, self.input_len], name=\"input_x\")\n",
        "        self.y = tf.placeholder(tf.float32, shape=[None], name=\"output_y\")\n",
        "        self.x_len = tf.placeholder(tf.int64, shape=[None], name=\"input_len\")\n",
        "\n",
        "        self.idx_sorted_1 = tf.placeholder(tf.int64, shape=[None], name=\"idx_sorted_1\")\n",
        "        self.idx_sorted_2 = tf.placeholder(tf.int64, shape=[None], name=\"idx_sorted_2\")\n",
        "\n",
        "        print('====================== Model 1 ======================')\n",
        "        self.model1 = My_LSTM(self.x, self.y, self.x_len, 32, 32, False, [], MAXLEN, CHARSIZE, 0.01)\n",
        "#         self.x_len1 = self.model1.x_len\n",
        "#         print('X_len 1 : ', self.x_len1)\n",
        "        print('====================== Model 2 ======================')\n",
        "        self.model2 = MyModel_CNN(self.x, self.y, 32, [[16, 3, -1], [16, 3, 3]], [], MAXLEN, CHARSIZE, 0.01)\n",
        "        \n",
        "        self.loss1 = self.model1.squared_error\n",
        "        self.loss2 = self.model2.squared_error\n",
        "\n",
        "        print('TMP Loss 1 : ', self.loss1)\n",
        "        print('TMP Loss 2 : ', self.loss2)            \n",
        "        \n",
        "        # Model Network....        \n",
        "        \n",
        "        self.pred_1 = self.model1.pred\n",
        "        self.pred_2 = self.model2.pred\n",
        "        \n",
        "        # Define loss        \n",
        "        self.train_loss1 = tf.reduce_mean(tf.gather(self.loss1, self.idx_sorted_2))\n",
        "        self.train_loss2 = tf.reduce_mean(tf.gather(self.loss2, self.idx_sorted_1))\n",
        "        print('Train Loss 1 : ', self.train_loss1)\n",
        "        print('Train Loss 2 : ', self.train_loss2)\n",
        "        \n",
        "        # train_step = \"optimize operation\"\n",
        "        optimizer_1 = tf.train.AdamOptimizer(learning_rate=self.lr)\n",
        "        optimizer_2 = tf.train.AdamOptimizer(learning_rate=self.lr)\n",
        "        self.train_step_1 = optimizer_1.minimize(self.train_loss1)\n",
        "        self.train_step_2 = optimizer_2.minimize(self.train_loss2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ao7Mm93tWyox",
        "colab_type": "code",
        "outputId": "86a13913-f57e-4e66-8620-9628f50a0ca5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        }
      },
      "source": [
        "MODEL_NAME = 'MY_MODEL2'\n",
        "\n",
        "if MODEL_NAME == 'LSTM':\n",
        "    model = LSTM(32, 32, False, [], MAXLEN, CHARSIZE, 0.01)\n",
        "    input_x = model.x\n",
        "    output_y = model.y\n",
        "    input_len = model.x_len\n",
        "    pred = model.pred\n",
        "    loss = model.loss\n",
        "    train_op = model.train_step\n",
        "elif MODEL_NAME == 'CNN':\n",
        "    model = Char_CNN(32, [[32, 3, -1], [32, 3, 3]], [], MAXLEN, CHARSIZE, 0.01)\n",
        "    input_x = model.x\n",
        "    output_y = model.y\n",
        "    pred = model.pred\n",
        "    loss = model.loss\n",
        "    train_op = model.train_step\n",
        "elif MODEL_NAME == 'MY_MODEL':\n",
        "    model = MyModel(32, [[16, 3, -1], [16, 3, 3]], [], MAXLEN, CHARSIZE, 0.0001)\n",
        "    input_x = model.x\n",
        "    output_y = model.y\n",
        "    pred = model.pred\n",
        "    loss = model.loss\n",
        "    train_op = model.train_step\n",
        "    output_keep_prob = model.output_keep_prob\n",
        "    \n",
        "elif MODEL_NAME == 'MY_MODEL2':\n",
        "    model= MyModel(32, [[16, 3, -1], [16, 3, 3]], [], MAXLEN, CHARSIZE, 0.0001) # 위에서 새롭게 정의한 것을 가져오기\n",
        "    input_x = model.x\n",
        "    output_y = model.y    \n",
        "\n",
        "    pred_1 = model.pred_1\n",
        "    loss_1 = model.loss1\n",
        "    train_loss_1 = model.train_loss1\n",
        "    idx_1 = model.idx_sorted_1\n",
        "    train_op_1 = model.train_step_1\n",
        "    input_len = model.x_len\n",
        "\n",
        "    pred_2 = model.pred_2\n",
        "    loss_2 = model.loss2\n",
        "    train_loss_2 = model.train_loss2\n",
        "    idx_2 = model.idx_sorted_2\n",
        "    train_op_2 = model.train_step_2\n",
        "    \n",
        "#     output_keep_prob = model.output_keep_prob\n",
        "else:\n",
        "    raise NotImplementedError"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "====================== Model 1 ======================\n",
            "====================== Model 2 ======================\n",
            "Embedding Matrix:  (340183, 32)\n",
            "CNN Input:  (?, 300, 32, 1)\n",
            "CNN Output:  (?, 298, 1, 16)\n",
            "CNN Input:  (?, 298, 16, 1)\n",
            "CNN Output:  (?, 296, 1, 16)\n",
            "Pooling Input:  (?, 296, 1, 16)\n",
            "Pooling Output:  (?, 98, 16, 1)\n",
            "out_shape[1].value:  98\n",
            "out_shape[2].value:  16\n",
            "fc_input:  Tensor(\"Reshape:0\", shape=(?, 1568), dtype=float32)\n",
            "Output Layer input:  (?, 1568)\n",
            "Output Layer output:  (?,)\n",
            "TMP Loss 1 :  Tensor(\"Loss/Square:0\", shape=(?,), dtype=float32)\n",
            "TMP Loss 2 :  Tensor(\"Loss_1/Square:0\", shape=(?,), dtype=float32)\n",
            "Train Loss 1 :  Tensor(\"Mean:0\", shape=(), dtype=float32)\n",
            "Train Loss 2 :  Tensor(\"Mean_1:0\", shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cg0vt77DWyoz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 학습 시작하기\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNM-eIlvpSCj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "56a94772-1c4d-4b99-fb52-c7747a0d894f"
      },
      "source": [
        "## LSTM RUNNING ###\n",
        "\n",
        "best_rmse = 1000000\n",
        "best_epoch = -1\n",
        "\n",
        "EPOCHs = 100\n",
        "DISPLAY_STEP = 50\n",
        "\n",
        "# TRAINING LOOP\n",
        "for epoch in range(1, EPOCHs + 1):\n",
        "    epoch_loss1 = 0.0\n",
        "    epoch_loss2 = 0.0\n",
        "    epoch_start = time.time()\n",
        "    # TRAIN EACH BATCH\n",
        "    for i, (train_x, train_y) in enumerate(train_dataset):\n",
        "        # PAD BATCH DATA\n",
        "        train_x_len = [len(x) for x in train_x]\n",
        "        train_x_pad = np.ones((len(train_x), MAXLEN), dtype=np.int32) * 2  # PAD : 2\n",
        "        for idx, s in enumerate(train_x):\n",
        "            length = len(s)\n",
        "            if length < MAXLEN:\n",
        "                train_x_pad[idx, :length] = np.array(s)\n",
        "            else:\n",
        "                train_x_pad[idx:, :MAXLEN] = np.array(s)[:MAXLEN]  # Truncate from the front\n",
        "        \n",
        "        # DEFINE feed_dict\n",
        "        # ex) feed_dict = {input_x: train_x_pad, output_y: train_y}\n",
        "        # feed_dict = {}\n",
        "        # feed_dict = {input_x: train_x_pad, output_y: train_y}\n",
        "        feed_dict = {input_x: train_x_pad, output_y: train_y, input_len: train_x_len}\n",
        "        tmp_loss_1, tmp_loss_2 = sess.run([loss_1, loss_2], feed_dict=feed_dict)\n",
        "\n",
        "        idx_sorted_1 = np.argsort(tmp_loss_1)[:100]\n",
        "        idx_sorted_2 = np.argsort(tmp_loss_2)[:100]\n",
        "        feed_dict = {input_x: train_x_pad, output_y: train_y, idx_1: idx_sorted_1, idx_2: idx_sorted_2, input_len: train_x_len}\n",
        "        \n",
        "        t = time.time()\n",
        "        # train_op: train, optimize\n",
        "        # loss : batch loss\n",
        "        _, l1 = sess.run([train_op_1, train_loss_1], feed_dict=feed_dict)\n",
        "        _, l2 = sess.run([train_op_2, train_loss_2], feed_dict=feed_dict)\n",
        "        elapsed = time.time() - t\n",
        "\n",
        "        epoch_loss1 += l1\n",
        "        epoch_loss2 += l2\n",
        "        \n",
        "        # PRINT LOSS\n",
        "        if (i + 1) % DISPLAY_STEP == 0:\n",
        "#             print(\"111111: \", train_dataset.num_batch, l1, elapsed)\n",
        "            print('[%3d/%3d] loss1 = %.4f, time elapsed = %.2f' % (i + 1, train_dataset.num_batch, l1, elapsed))\n",
        "            print('[%3d/%3d] loss2 = %.4f, time elapsed = %.2f' % (i + 1, train_dataset.num_batch, l2, elapsed))\n",
        "    epoch_end = time.time() - epoch_start\n",
        "    print('Epoch %3d >> Epoch loss1: %.4f , time elapsed %.4f' % (epoch, epoch_loss1, epoch_end))\n",
        "    print('Epoch %3d >> Epoch loss2: %.4f , time elapsed %.4f' % (epoch, epoch_loss2, epoch_end))\n",
        "    \n",
        "    # EVALUATE ON TEST DATA \n",
        "    se_1 = 0\n",
        "    se_2 = 0\n",
        "    total_1 = 0\n",
        "    total_2 = 0\n",
        "    for i, (test_x, test_y) in enumerate(test_dataset):\n",
        "        # PAD\n",
        "        test_x_len = [len(x) for x in test_x]\n",
        "        test_x_pad = np.ones((len(test_x), MAXLEN), dtype=np.int32) * 2  # PAD : 2\n",
        "        for idx, s in enumerate(test_x):\n",
        "            length = len(s)\n",
        "            if length < MAXLEN:\n",
        "                test_x_pad[idx, :length] = np.array(s)\n",
        "            else:\n",
        "                test_x_pad[idx:, :MAXLEN] = np.array(s)[:MAXLEN]  # Truncate from the front\n",
        "            \n",
        "        # feed_dict \n",
        "        # feed_dict = {}\n",
        "#         feed_dict = {input_x: test_x_pad}\n",
        "        feed_dict = {input_x: test_x_pad, input_len: test_x_len}\n",
        "        p_1, p_2 = sess.run([pred_1, pred_2], feed_dict=feed_dict)\n",
        "        \n",
        "        # squared error\n",
        "        se_1 += np.sum(np.square(p_1 - test_y))\n",
        "        se_2 += np.sum(np.square(p_2 - test_y))\n",
        "        total_1 += len(p_1)\n",
        "        total_2 += len(p_2)\n",
        "\n",
        "    # root mean squared error\n",
        "    test_rmse_1 = np.sqrt(se_1 / total_1)\n",
        "    test_rmse_2 = np.sqrt(se_2 / total_2)\n",
        "    print('Test RMSE 1 = %.4f, RMSE 2 = %.4f' % (test_rmse_1, test_rmse_2))\n",
        "    \n",
        "    if best_rmse > test_rmse_1:\n",
        "        best_rmse = test_rmse_1\n",
        "        best_epoch = epoch\n",
        "        \n",
        "    if best_rmse > test_rmse_2:\n",
        "        best_rmse = test_rmse_2\n",
        "        best_epoch = epoch"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 50/157] loss1 = 4.2347, time elapsed = 0.27\n",
            "[ 50/157] loss2 = 4.1360, time elapsed = 0.27\n",
            "[100/157] loss1 = 4.7592, time elapsed = 0.28\n",
            "[100/157] loss2 = 4.4679, time elapsed = 0.28\n",
            "[150/157] loss1 = 3.7254, time elapsed = 0.27\n",
            "[150/157] loss2 = 2.3984, time elapsed = 0.27\n",
            "Epoch   1 >> Epoch loss1: 752.4133 , time elapsed 61.0098\n",
            "Epoch   1 >> Epoch loss2: 691.3803 , time elapsed 61.0098\n",
            "Test RMSE 1 = 6.2188, RMSE 2 = 5.7329\n",
            "[ 50/157] loss1 = 2.5854, time elapsed = 0.27\n",
            "[ 50/157] loss2 = 0.7119, time elapsed = 0.27\n",
            "[100/157] loss1 = 3.9304, time elapsed = 0.27\n",
            "[100/157] loss2 = 1.4525, time elapsed = 0.27\n",
            "[150/157] loss1 = 2.3036, time elapsed = 0.28\n",
            "[150/157] loss2 = 0.8430, time elapsed = 0.28\n",
            "Epoch   2 >> Epoch loss1: 500.6225 , time elapsed 60.4023\n",
            "Epoch   2 >> Epoch loss2: 197.2066 , time elapsed 60.4023\n",
            "Test RMSE 1 = 5.8452, RMSE 2 = 4.9640\n",
            "[ 50/157] loss1 = 3.1272, time elapsed = 0.28\n",
            "[ 50/157] loss2 = 1.4280, time elapsed = 0.28\n",
            "[100/157] loss1 = 2.3763, time elapsed = 0.27\n",
            "[100/157] loss2 = 1.1624, time elapsed = 0.27\n",
            "[150/157] loss1 = 2.1069, time elapsed = 0.27\n",
            "[150/157] loss2 = 1.1399, time elapsed = 0.27\n",
            "Epoch   3 >> Epoch loss1: 360.1687 , time elapsed 60.5685\n",
            "Epoch   3 >> Epoch loss2: 185.9563 , time elapsed 60.5685\n",
            "Test RMSE 1 = 5.5796, RMSE 2 = 4.9167\n",
            "[ 50/157] loss1 = 1.4134, time elapsed = 0.27\n",
            "[ 50/157] loss2 = 0.9917, time elapsed = 0.27\n",
            "[100/157] loss1 = 1.7425, time elapsed = 0.27\n",
            "[100/157] loss2 = 0.9861, time elapsed = 0.27\n",
            "[150/157] loss1 = 1.4146, time elapsed = 0.28\n",
            "[150/157] loss2 = 0.8990, time elapsed = 0.28\n",
            "Epoch   4 >> Epoch loss1: 287.6877 , time elapsed 60.6960\n",
            "Epoch   4 >> Epoch loss2: 189.5184 , time elapsed 60.6960\n",
            "Test RMSE 1 = 5.3989, RMSE 2 = 4.8735\n",
            "[ 50/157] loss1 = 1.7198, time elapsed = 0.27\n",
            "[ 50/157] loss2 = 1.2844, time elapsed = 0.27\n",
            "[100/157] loss1 = 1.7876, time elapsed = 0.27\n",
            "[100/157] loss2 = 1.3159, time elapsed = 0.27\n",
            "[150/157] loss1 = 1.3770, time elapsed = 0.27\n",
            "[150/157] loss2 = 1.0321, time elapsed = 0.27\n",
            "Epoch   5 >> Epoch loss1: 254.4297 , time elapsed 60.6636\n",
            "Epoch   5 >> Epoch loss2: 187.7254 , time elapsed 60.6636\n",
            "Test RMSE 1 = 5.2919, RMSE 2 = 4.9083\n",
            "[ 50/157] loss1 = 1.4137, time elapsed = 0.27\n",
            "[ 50/157] loss2 = 1.1203, time elapsed = 0.27\n",
            "[100/157] loss1 = 1.3055, time elapsed = 0.28\n",
            "[100/157] loss2 = 0.9403, time elapsed = 0.28\n",
            "[150/157] loss1 = 1.6094, time elapsed = 0.28\n",
            "[150/157] loss2 = 1.2594, time elapsed = 0.28\n",
            "Epoch   6 >> Epoch loss1: 252.5244 , time elapsed 60.1997\n",
            "Epoch   6 >> Epoch loss2: 196.6630 , time elapsed 60.1997\n",
            "Test RMSE 1 = 5.2278, RMSE 2 = 4.8427\n",
            "[ 50/157] loss1 = 1.6488, time elapsed = 0.28\n",
            "[ 50/157] loss2 = 1.1179, time elapsed = 0.28\n",
            "[100/157] loss1 = 1.5092, time elapsed = 0.27\n",
            "[100/157] loss2 = 1.1138, time elapsed = 0.27\n",
            "[150/157] loss1 = 1.2436, time elapsed = 0.28\n",
            "[150/157] loss2 = 0.8863, time elapsed = 0.28\n",
            "Epoch   7 >> Epoch loss1: 243.5547 , time elapsed 60.3602\n",
            "Epoch   7 >> Epoch loss2: 190.7733 , time elapsed 60.3602\n",
            "Test RMSE 1 = 5.1891, RMSE 2 = 4.8536\n",
            "[ 50/157] loss1 = 1.1081, time elapsed = 0.27\n",
            "[ 50/157] loss2 = 0.9703, time elapsed = 0.27\n",
            "[100/157] loss1 = 1.7688, time elapsed = 0.27\n",
            "[100/157] loss2 = 1.1844, time elapsed = 0.27\n",
            "[150/157] loss1 = 0.9903, time elapsed = 0.28\n",
            "[150/157] loss2 = 0.8851, time elapsed = 0.28\n",
            "Epoch   8 >> Epoch loss1: 247.3228 , time elapsed 61.2801\n",
            "Epoch   8 >> Epoch loss2: 193.3902 , time elapsed 61.2801\n",
            "Test RMSE 1 = 5.1741, RMSE 2 = 4.8183\n",
            "[ 50/157] loss1 = 1.3595, time elapsed = 0.28\n",
            "[ 50/157] loss2 = 0.9876, time elapsed = 0.28\n",
            "[100/157] loss1 = 1.3574, time elapsed = 0.27\n",
            "[100/157] loss2 = 1.1045, time elapsed = 0.27\n",
            "[150/157] loss1 = 1.4301, time elapsed = 0.26\n",
            "[150/157] loss2 = 1.1448, time elapsed = 0.26\n",
            "Epoch   9 >> Epoch loss1: 244.0441 , time elapsed 60.8770\n",
            "Epoch   9 >> Epoch loss2: 190.8692 , time elapsed 60.8770\n",
            "Test RMSE 1 = 5.1688, RMSE 2 = 4.8471\n",
            "[ 50/157] loss1 = 1.5197, time elapsed = 0.27\n",
            "[ 50/157] loss2 = 1.3234, time elapsed = 0.27\n",
            "[100/157] loss1 = 1.2302, time elapsed = 0.28\n",
            "[100/157] loss2 = 0.8588, time elapsed = 0.28\n",
            "[150/157] loss1 = 1.2576, time elapsed = 0.29\n",
            "[150/157] loss2 = 0.9955, time elapsed = 0.29\n",
            "Epoch  10 >> Epoch loss1: 239.0480 , time elapsed 60.7138\n",
            "Epoch  10 >> Epoch loss2: 185.9192 , time elapsed 60.7138\n",
            "Test RMSE 1 = 5.1633, RMSE 2 = 4.8243\n",
            "[ 50/157] loss1 = 1.7982, time elapsed = 0.28\n",
            "[ 50/157] loss2 = 1.2012, time elapsed = 0.28\n",
            "[100/157] loss1 = 1.1068, time elapsed = 0.28\n",
            "[100/157] loss2 = 0.8300, time elapsed = 0.28\n",
            "[150/157] loss1 = 2.0198, time elapsed = 0.29\n",
            "[150/157] loss2 = 1.3816, time elapsed = 0.29\n",
            "Epoch  11 >> Epoch loss1: 236.3645 , time elapsed 60.5386\n",
            "Epoch  11 >> Epoch loss2: 181.2067 , time elapsed 60.5386\n",
            "Test RMSE 1 = 5.1616, RMSE 2 = 4.8227\n",
            "[ 50/157] loss1 = 1.6241, time elapsed = 0.27\n",
            "[ 50/157] loss2 = 1.3995, time elapsed = 0.27\n",
            "[100/157] loss1 = 1.0580, time elapsed = 0.27\n",
            "[100/157] loss2 = 0.8757, time elapsed = 0.27\n",
            "[150/157] loss1 = 1.2403, time elapsed = 0.28\n",
            "[150/157] loss2 = 0.8421, time elapsed = 0.28\n",
            "Epoch  12 >> Epoch loss1: 238.3516 , time elapsed 61.0652\n",
            "Epoch  12 >> Epoch loss2: 179.1356 , time elapsed 61.0652\n",
            "Test RMSE 1 = 5.1608, RMSE 2 = 4.8043\n",
            "[ 50/157] loss1 = 1.9985, time elapsed = 0.27\n",
            "[ 50/157] loss2 = 1.3883, time elapsed = 0.27\n",
            "[100/157] loss1 = 1.0571, time elapsed = 0.27\n",
            "[100/157] loss2 = 0.8554, time elapsed = 0.27\n",
            "[150/157] loss1 = 1.3525, time elapsed = 0.26\n",
            "[150/157] loss2 = 0.9478, time elapsed = 0.26\n",
            "Epoch  13 >> Epoch loss1: 232.6432 , time elapsed 60.3063\n",
            "Epoch  13 >> Epoch loss2: 170.6193 , time elapsed 60.3063\n",
            "Test RMSE 1 = 5.1589, RMSE 2 = 4.8226\n",
            "[ 50/157] loss1 = 1.2438, time elapsed = 0.27\n",
            "[ 50/157] loss2 = 0.9205, time elapsed = 0.27\n",
            "[100/157] loss1 = 0.9401, time elapsed = 0.28\n",
            "[100/157] loss2 = 0.7014, time elapsed = 0.28\n",
            "[150/157] loss1 = 1.1573, time elapsed = 0.27\n",
            "[150/157] loss2 = 0.7177, time elapsed = 0.27\n",
            "Epoch  14 >> Epoch loss1: 236.0911 , time elapsed 60.4480\n",
            "Epoch  14 >> Epoch loss2: 168.0438 , time elapsed 60.4480\n",
            "Test RMSE 1 = 5.1565, RMSE 2 = 4.7826\n",
            "[ 50/157] loss1 = 1.4242, time elapsed = 0.27\n",
            "[ 50/157] loss2 = 0.9672, time elapsed = 0.27\n",
            "[100/157] loss1 = 1.3443, time elapsed = 0.26\n",
            "[100/157] loss2 = 0.8955, time elapsed = 0.26\n",
            "[150/157] loss1 = 1.0923, time elapsed = 0.27\n",
            "[150/157] loss2 = 1.0118, time elapsed = 0.27\n",
            "Epoch  15 >> Epoch loss1: 235.6403 , time elapsed 60.1502\n",
            "Epoch  15 >> Epoch loss2: 165.6215 , time elapsed 60.1502\n",
            "Test RMSE 1 = 5.1580, RMSE 2 = 4.7906\n",
            "[ 50/157] loss1 = 1.5408, time elapsed = 0.29\n",
            "[ 50/157] loss2 = 0.9753, time elapsed = 0.29\n",
            "[100/157] loss1 = 1.4358, time elapsed = 0.27\n",
            "[100/157] loss2 = 0.8033, time elapsed = 0.27\n",
            "[150/157] loss1 = 1.1785, time elapsed = 0.27\n",
            "[150/157] loss2 = 0.6563, time elapsed = 0.27\n",
            "Epoch  16 >> Epoch loss1: 236.5802 , time elapsed 60.1776\n",
            "Epoch  16 >> Epoch loss2: 160.3196 , time elapsed 60.1776\n",
            "Test RMSE 1 = 5.1498, RMSE 2 = 4.7456\n",
            "[ 50/157] loss1 = 1.2439, time elapsed = 0.27\n",
            "[ 50/157] loss2 = 0.7419, time elapsed = 0.27\n",
            "[100/157] loss1 = 1.6871, time elapsed = 0.27\n",
            "[100/157] loss2 = 0.8150, time elapsed = 0.27\n",
            "[150/157] loss1 = 1.6839, time elapsed = 0.28\n",
            "[150/157] loss2 = 0.8478, time elapsed = 0.28\n",
            "Epoch  17 >> Epoch loss1: 235.7631 , time elapsed 60.0546\n",
            "Epoch  17 >> Epoch loss2: 153.3832 , time elapsed 60.0546\n",
            "Test RMSE 1 = 5.1415, RMSE 2 = 4.7587\n",
            "[ 50/157] loss1 = 1.2061, time elapsed = 0.27\n",
            "[ 50/157] loss2 = 0.7998, time elapsed = 0.27\n",
            "[100/157] loss1 = 1.4282, time elapsed = 0.26\n",
            "[100/157] loss2 = 0.6481, time elapsed = 0.26\n",
            "[150/157] loss1 = 1.6092, time elapsed = 0.30\n",
            "[150/157] loss2 = 1.1297, time elapsed = 0.30\n",
            "Epoch  18 >> Epoch loss1: 231.4569 , time elapsed 60.0721\n",
            "Epoch  18 >> Epoch loss2: 144.5947 , time elapsed 60.0721\n",
            "Test RMSE 1 = 5.1371, RMSE 2 = 4.7437\n",
            "[ 50/157] loss1 = 1.8093, time elapsed = 0.27\n",
            "[ 50/157] loss2 = 0.9274, time elapsed = 0.27\n",
            "[100/157] loss1 = 1.5770, time elapsed = 0.28\n",
            "[100/157] loss2 = 1.0375, time elapsed = 0.28\n",
            "[150/157] loss1 = 1.3937, time elapsed = 0.27\n",
            "[150/157] loss2 = 0.6260, time elapsed = 0.27\n",
            "Epoch  19 >> Epoch loss1: 237.1224 , time elapsed 59.9437\n",
            "Epoch  19 >> Epoch loss2: 140.2758 , time elapsed 59.9437\n",
            "Test RMSE 1 = 5.1276, RMSE 2 = 4.7183\n",
            "[ 50/157] loss1 = 1.3542, time elapsed = 0.27\n",
            "[ 50/157] loss2 = 0.7314, time elapsed = 0.27\n",
            "[100/157] loss1 = 1.2689, time elapsed = 0.29\n",
            "[100/157] loss2 = 0.5258, time elapsed = 0.29\n",
            "[150/157] loss1 = 1.2244, time elapsed = 0.29\n",
            "[150/157] loss2 = 0.6472, time elapsed = 0.29\n",
            "Epoch  20 >> Epoch loss1: 237.5710 , time elapsed 59.8573\n",
            "Epoch  20 >> Epoch loss2: 133.3478 , time elapsed 59.8573\n",
            "Test RMSE 1 = 5.1211, RMSE 2 = 4.6812\n",
            "[ 50/157] loss1 = 1.3121, time elapsed = 0.30\n",
            "[ 50/157] loss2 = 0.7042, time elapsed = 0.30\n",
            "[100/157] loss1 = 0.9685, time elapsed = 0.29\n",
            "[100/157] loss2 = 0.5956, time elapsed = 0.29\n",
            "[150/157] loss1 = 1.4231, time elapsed = 0.27\n",
            "[150/157] loss2 = 0.6220, time elapsed = 0.27\n",
            "Epoch  21 >> Epoch loss1: 233.3673 , time elapsed 64.2936\n",
            "Epoch  21 >> Epoch loss2: 121.0310 , time elapsed 64.2936\n",
            "Test RMSE 1 = 5.1117, RMSE 2 = 4.7153\n",
            "[ 50/157] loss1 = 1.0665, time elapsed = 0.30\n",
            "[ 50/157] loss2 = 0.4425, time elapsed = 0.30\n",
            "[100/157] loss1 = 1.4754, time elapsed = 0.28\n",
            "[100/157] loss2 = 0.6944, time elapsed = 0.28\n",
            "[150/157] loss1 = 1.2775, time elapsed = 0.27\n",
            "[150/157] loss2 = 0.5053, time elapsed = 0.27\n",
            "Epoch  22 >> Epoch loss1: 229.6835 , time elapsed 59.9885\n",
            "Epoch  22 >> Epoch loss2: 113.6855 , time elapsed 59.9885\n",
            "Test RMSE 1 = 5.1072, RMSE 2 = 4.7021\n",
            "[ 50/157] loss1 = 1.4277, time elapsed = 0.30\n",
            "[ 50/157] loss2 = 0.6635, time elapsed = 0.30\n",
            "[100/157] loss1 = 1.2180, time elapsed = 0.26\n",
            "[100/157] loss2 = 0.4639, time elapsed = 0.26\n",
            "[150/157] loss1 = 0.8702, time elapsed = 0.27\n",
            "[150/157] loss2 = 0.4482, time elapsed = 0.27\n",
            "Epoch  23 >> Epoch loss1: 234.5981 , time elapsed 60.1508\n",
            "Epoch  23 >> Epoch loss2: 107.9930 , time elapsed 60.1508\n",
            "Test RMSE 1 = 5.0966, RMSE 2 = 4.6832\n",
            "[ 50/157] loss1 = 1.1540, time elapsed = 0.27\n",
            "[ 50/157] loss2 = 0.3334, time elapsed = 0.27\n",
            "[100/157] loss1 = 1.1603, time elapsed = 0.27\n",
            "[100/157] loss2 = 0.5077, time elapsed = 0.27\n",
            "[150/157] loss1 = 1.3087, time elapsed = 0.27\n",
            "[150/157] loss2 = 0.4128, time elapsed = 0.27\n",
            "Epoch  24 >> Epoch loss1: 233.5626 , time elapsed 59.7403\n",
            "Epoch  24 >> Epoch loss2: 104.2263 , time elapsed 59.7403\n",
            "Test RMSE 1 = 5.0922, RMSE 2 = 4.7118\n",
            "[ 50/157] loss1 = 1.4393, time elapsed = 0.28\n",
            "[ 50/157] loss2 = 0.6169, time elapsed = 0.28\n",
            "[100/157] loss1 = 1.1489, time elapsed = 0.27\n",
            "[100/157] loss2 = 0.5157, time elapsed = 0.27\n",
            "[150/157] loss1 = 1.5176, time elapsed = 0.28\n",
            "[150/157] loss2 = 0.6394, time elapsed = 0.28\n",
            "Epoch  25 >> Epoch loss1: 234.8227 , time elapsed 78.7413\n",
            "Epoch  25 >> Epoch loss2: 100.2043 , time elapsed 78.7413\n",
            "Test RMSE 1 = 5.0899, RMSE 2 = 4.7047\n",
            "[ 50/157] loss1 = 1.5002, time elapsed = 0.26\n",
            "[ 50/157] loss2 = 0.3792, time elapsed = 0.26\n",
            "[100/157] loss1 = 0.9748, time elapsed = 0.27\n",
            "[100/157] loss2 = 0.4451, time elapsed = 0.27\n",
            "[150/157] loss1 = 1.3555, time elapsed = 0.27\n",
            "[150/157] loss2 = 0.4452, time elapsed = 0.27\n",
            "Epoch  26 >> Epoch loss1: 223.4323 , time elapsed 67.9405\n",
            "Epoch  26 >> Epoch loss2: 84.1056 , time elapsed 67.9405\n",
            "Test RMSE 1 = 5.0873, RMSE 2 = 4.7447\n",
            "[ 50/157] loss1 = 1.4183, time elapsed = 0.27\n",
            "[ 50/157] loss2 = 0.4686, time elapsed = 0.27\n",
            "[100/157] loss1 = 1.2761, time elapsed = 0.26\n",
            "[100/157] loss2 = 0.3847, time elapsed = 0.26\n",
            "[150/157] loss1 = 1.2762, time elapsed = 0.27\n",
            "[150/157] loss2 = 0.4949, time elapsed = 0.27\n",
            "Epoch  27 >> Epoch loss1: 231.3746 , time elapsed 60.4299\n",
            "Epoch  27 >> Epoch loss2: 87.4790 , time elapsed 60.4299\n",
            "Test RMSE 1 = 5.0876, RMSE 2 = 4.7217\n",
            "[ 50/157] loss1 = 1.2113, time elapsed = 0.28\n",
            "[ 50/157] loss2 = 0.2976, time elapsed = 0.28\n",
            "[100/157] loss1 = 1.2422, time elapsed = 0.28\n",
            "[100/157] loss2 = 0.2771, time elapsed = 0.28\n",
            "[150/157] loss1 = 1.1463, time elapsed = 0.27\n",
            "[150/157] loss2 = 0.2867, time elapsed = 0.27\n",
            "Epoch  28 >> Epoch loss1: 221.9584 , time elapsed 59.7677\n",
            "Epoch  28 >> Epoch loss2: 76.2834 , time elapsed 59.7677\n",
            "Test RMSE 1 = 5.0809, RMSE 2 = 4.7247\n",
            "[ 50/157] loss1 = 1.1085, time elapsed = 0.28\n",
            "[ 50/157] loss2 = 0.2262, time elapsed = 0.28\n",
            "[100/157] loss1 = 1.2658, time elapsed = 0.26\n",
            "[100/157] loss2 = 0.3919, time elapsed = 0.26\n",
            "[150/157] loss1 = 1.2128, time elapsed = 0.28\n",
            "[150/157] loss2 = 0.2653, time elapsed = 0.28\n",
            "Epoch  29 >> Epoch loss1: 222.3829 , time elapsed 59.6845\n",
            "Epoch  29 >> Epoch loss2: 73.3764 , time elapsed 59.6845\n",
            "Test RMSE 1 = 5.0765, RMSE 2 = 4.7148\n",
            "[ 50/157] loss1 = 1.3919, time elapsed = 0.28\n",
            "[ 50/157] loss2 = 0.3689, time elapsed = 0.28\n",
            "[100/157] loss1 = 1.1527, time elapsed = 0.27\n",
            "[100/157] loss2 = 0.3163, time elapsed = 0.27\n",
            "[150/157] loss1 = 1.4866, time elapsed = 0.27\n",
            "[150/157] loss2 = 0.6316, time elapsed = 0.27\n",
            "Epoch  30 >> Epoch loss1: 218.3136 , time elapsed 59.6937\n",
            "Epoch  30 >> Epoch loss2: 68.3536 , time elapsed 59.6937\n",
            "Test RMSE 1 = 5.0733, RMSE 2 = 4.7200\n",
            "[ 50/157] loss1 = 1.4459, time elapsed = 0.27\n",
            "[ 50/157] loss2 = 0.3618, time elapsed = 0.27\n",
            "[100/157] loss1 = 1.0659, time elapsed = 0.27\n",
            "[100/157] loss2 = 0.2341, time elapsed = 0.27\n",
            "[150/157] loss1 = 1.1271, time elapsed = 0.28\n",
            "[150/157] loss2 = 0.1991, time elapsed = 0.28\n",
            "Epoch  31 >> Epoch loss1: 220.4851 , time elapsed 59.7555\n",
            "Epoch  31 >> Epoch loss2: 66.1134 , time elapsed 59.7555\n",
            "Test RMSE 1 = 5.0687, RMSE 2 = 4.7243\n",
            "[ 50/157] loss1 = 1.1366, time elapsed = 0.27\n",
            "[ 50/157] loss2 = 0.1977, time elapsed = 0.27\n",
            "[100/157] loss1 = 1.3630, time elapsed = 0.28\n",
            "[100/157] loss2 = 0.2772, time elapsed = 0.28\n",
            "[150/157] loss1 = 1.4161, time elapsed = 0.26\n",
            "[150/157] loss2 = 0.3241, time elapsed = 0.26\n",
            "Epoch  32 >> Epoch loss1: 225.9597 , time elapsed 60.4763\n",
            "Epoch  32 >> Epoch loss2: 68.1774 , time elapsed 60.4763\n",
            "Test RMSE 1 = 5.0666, RMSE 2 = 4.7141\n",
            "[ 50/157] loss1 = 1.0225, time elapsed = 0.26\n",
            "[ 50/157] loss2 = 0.1501, time elapsed = 0.26\n",
            "[100/157] loss1 = 1.6777, time elapsed = 0.27\n",
            "[100/157] loss2 = 0.3961, time elapsed = 0.27\n",
            "[150/157] loss1 = 1.2898, time elapsed = 0.27\n",
            "[150/157] loss2 = 0.2549, time elapsed = 0.27\n",
            "Epoch  33 >> Epoch loss1: 223.4576 , time elapsed 59.5442\n",
            "Epoch  33 >> Epoch loss2: 63.9565 , time elapsed 59.5442\n",
            "Test RMSE 1 = 5.0675, RMSE 2 = 4.7382\n",
            "[ 50/157] loss1 = 1.3334, time elapsed = 0.26\n",
            "[ 50/157] loss2 = 0.1652, time elapsed = 0.26\n",
            "[100/157] loss1 = 1.1661, time elapsed = 0.27\n",
            "[100/157] loss2 = 0.1900, time elapsed = 0.27\n",
            "[150/157] loss1 = 1.7272, time elapsed = 0.27\n",
            "[150/157] loss2 = 0.4591, time elapsed = 0.27\n",
            "Epoch  34 >> Epoch loss1: 213.4352 , time elapsed 59.4146\n",
            "Epoch  34 >> Epoch loss2: 54.0564 , time elapsed 59.4146\n",
            "Test RMSE 1 = 5.0655, RMSE 2 = 4.7411\n",
            "[ 50/157] loss1 = 1.2600, time elapsed = 0.26\n",
            "[ 50/157] loss2 = 0.1681, time elapsed = 0.26\n",
            "[100/157] loss1 = 1.3218, time elapsed = 0.26\n",
            "[100/157] loss2 = 0.2506, time elapsed = 0.26\n",
            "[150/157] loss1 = 1.3840, time elapsed = 0.28\n",
            "[150/157] loss2 = 0.1638, time elapsed = 0.28\n",
            "Epoch  35 >> Epoch loss1: 221.4741 , time elapsed 59.3312\n",
            "Epoch  35 >> Epoch loss2: 61.1616 , time elapsed 59.3312\n",
            "Test RMSE 1 = 5.0660, RMSE 2 = 4.7336\n",
            "[ 50/157] loss1 = 1.1382, time elapsed = 0.27\n",
            "[ 50/157] loss2 = 0.1526, time elapsed = 0.27\n",
            "[100/157] loss1 = 1.4639, time elapsed = 0.26\n",
            "[100/157] loss2 = 0.3395, time elapsed = 0.26\n",
            "[150/157] loss1 = 1.6584, time elapsed = 0.28\n",
            "[150/157] loss2 = 0.3939, time elapsed = 0.28\n",
            "Epoch  36 >> Epoch loss1: 212.6454 , time elapsed 59.4244\n",
            "Epoch  36 >> Epoch loss2: 51.4452 , time elapsed 59.4244\n",
            "Test RMSE 1 = 5.0669, RMSE 2 = 4.7395\n",
            "[ 50/157] loss1 = 1.0539, time elapsed = 0.26\n",
            "[ 50/157] loss2 = 0.1416, time elapsed = 0.26\n",
            "[100/157] loss1 = 1.1398, time elapsed = 0.28\n",
            "[100/157] loss2 = 0.1442, time elapsed = 0.28\n",
            "[150/157] loss1 = 1.2980, time elapsed = 0.28\n",
            "[150/157] loss2 = 0.2344, time elapsed = 0.28\n",
            "Epoch  37 >> Epoch loss1: 215.4470 , time elapsed 59.8625\n",
            "Epoch  37 >> Epoch loss2: 53.4408 , time elapsed 59.8625\n",
            "Test RMSE 1 = 5.0594, RMSE 2 = 4.7275\n",
            "[ 50/157] loss1 = 0.8749, time elapsed = 0.28\n",
            "[ 50/157] loss2 = 0.1440, time elapsed = 0.28\n",
            "[100/157] loss1 = 0.9216, time elapsed = 0.27\n",
            "[100/157] loss2 = 0.1644, time elapsed = 0.27\n",
            "[150/157] loss1 = 1.2911, time elapsed = 0.27\n",
            "[150/157] loss2 = 0.1491, time elapsed = 0.27\n",
            "Epoch  38 >> Epoch loss1: 215.9224 , time elapsed 59.5699\n",
            "Epoch  38 >> Epoch loss2: 52.2253 , time elapsed 59.5699\n",
            "Test RMSE 1 = 5.0533, RMSE 2 = 4.7339\n",
            "[ 50/157] loss1 = 1.2838, time elapsed = 0.27\n",
            "[ 50/157] loss2 = 0.0889, time elapsed = 0.27\n",
            "[100/157] loss1 = 1.4297, time elapsed = 0.26\n",
            "[100/157] loss2 = 0.1083, time elapsed = 0.26\n",
            "[150/157] loss1 = 1.2915, time elapsed = 0.26\n",
            "[150/157] loss2 = 0.2519, time elapsed = 0.26\n",
            "Epoch  39 >> Epoch loss1: 220.1670 , time elapsed 59.3091\n",
            "Epoch  39 >> Epoch loss2: 55.8985 , time elapsed 59.3091\n",
            "Test RMSE 1 = 5.0527, RMSE 2 = 4.7684\n",
            "[ 50/157] loss1 = 1.1496, time elapsed = 0.26\n",
            "[ 50/157] loss2 = 0.1521, time elapsed = 0.26\n",
            "[100/157] loss1 = 0.8956, time elapsed = 0.29\n",
            "[100/157] loss2 = 0.0902, time elapsed = 0.29\n",
            "[150/157] loss1 = 1.2671, time elapsed = 0.27\n",
            "[150/157] loss2 = 0.1266, time elapsed = 0.27\n",
            "Epoch  40 >> Epoch loss1: 204.9040 , time elapsed 59.3075\n",
            "Epoch  40 >> Epoch loss2: 46.5476 , time elapsed 59.3075\n",
            "Test RMSE 1 = 5.0534, RMSE 2 = 4.7603\n",
            "[ 50/157] loss1 = 1.0317, time elapsed = 0.27\n",
            "[ 50/157] loss2 = 0.1369, time elapsed = 0.27\n",
            "[100/157] loss1 = 0.8131, time elapsed = 0.28\n",
            "[100/157] loss2 = 0.0875, time elapsed = 0.28\n",
            "[150/157] loss1 = 1.1360, time elapsed = 0.27\n",
            "[150/157] loss2 = 0.1203, time elapsed = 0.27\n",
            "Epoch  41 >> Epoch loss1: 205.9226 , time elapsed 59.3030\n",
            "Epoch  41 >> Epoch loss2: 51.1729 , time elapsed 59.3030\n",
            "Test RMSE 1 = 5.0344, RMSE 2 = 4.7502\n",
            "[ 50/157] loss1 = 0.9641, time elapsed = 0.29\n",
            "[ 50/157] loss2 = 0.0877, time elapsed = 0.29\n",
            "[100/157] loss1 = 1.1271, time elapsed = 0.27\n",
            "[100/157] loss2 = 0.1492, time elapsed = 0.27\n",
            "[150/157] loss1 = 1.0612, time elapsed = 0.28\n",
            "[150/157] loss2 = 0.2024, time elapsed = 0.28\n",
            "Epoch  42 >> Epoch loss1: 199.7992 , time elapsed 59.7877\n",
            "Epoch  42 >> Epoch loss2: 47.4483 , time elapsed 59.7877\n",
            "Test RMSE 1 = 5.0124, RMSE 2 = 4.7352\n",
            "[ 50/157] loss1 = 0.8975, time elapsed = 0.28\n",
            "[ 50/157] loss2 = 0.0738, time elapsed = 0.28\n",
            "[100/157] loss1 = 0.8351, time elapsed = 0.27\n",
            "[100/157] loss2 = 0.0808, time elapsed = 0.27\n",
            "[150/157] loss1 = 1.0407, time elapsed = 0.27\n",
            "[150/157] loss2 = 0.1380, time elapsed = 0.27\n",
            "Epoch  43 >> Epoch loss1: 188.6913 , time elapsed 59.5398\n",
            "Epoch  43 >> Epoch loss2: 52.2083 , time elapsed 59.5398\n",
            "Test RMSE 1 = 4.9606, RMSE 2 = 4.7526\n",
            "[ 50/157] loss1 = 0.7567, time elapsed = 0.27\n",
            "[ 50/157] loss2 = 0.0926, time elapsed = 0.27\n",
            "[100/157] loss1 = 0.6312, time elapsed = 0.26\n",
            "[100/157] loss2 = 0.0900, time elapsed = 0.26\n",
            "[150/157] loss1 = 0.8182, time elapsed = 0.26\n",
            "[150/157] loss2 = 0.0941, time elapsed = 0.26\n",
            "Epoch  44 >> Epoch loss1: 161.3344 , time elapsed 59.3575\n",
            "Epoch  44 >> Epoch loss2: 43.2597 , time elapsed 59.3575\n",
            "Test RMSE 1 = 4.9678, RMSE 2 = 4.7506\n",
            "[ 50/157] loss1 = 0.9741, time elapsed = 0.26\n",
            "[ 50/157] loss2 = 0.1775, time elapsed = 0.26\n",
            "[100/157] loss1 = 0.7245, time elapsed = 0.27\n",
            "[100/157] loss2 = 0.1099, time elapsed = 0.27\n",
            "[150/157] loss1 = 1.0164, time elapsed = 0.26\n",
            "[150/157] loss2 = 0.2719, time elapsed = 0.26\n",
            "Epoch  45 >> Epoch loss1: 153.8367 , time elapsed 59.3073\n",
            "Epoch  45 >> Epoch loss2: 50.0303 , time elapsed 59.3073\n",
            "Test RMSE 1 = 4.9296, RMSE 2 = 4.7373\n",
            "[ 50/157] loss1 = 0.5938, time elapsed = 0.27\n",
            "[ 50/157] loss2 = 0.1007, time elapsed = 0.27\n",
            "[100/157] loss1 = 0.5459, time elapsed = 0.28\n",
            "[100/157] loss2 = 0.1058, time elapsed = 0.28\n",
            "[150/157] loss1 = 0.8445, time elapsed = 0.27\n",
            "[150/157] loss2 = 0.1952, time elapsed = 0.27\n",
            "Epoch  46 >> Epoch loss1: 140.7235 , time elapsed 59.5300\n",
            "Epoch  46 >> Epoch loss2: 46.1736 , time elapsed 59.5300\n",
            "Test RMSE 1 = 4.9325, RMSE 2 = 4.7270\n",
            "[ 50/157] loss1 = 0.5116, time elapsed = 0.26\n",
            "[ 50/157] loss2 = 0.0689, time elapsed = 0.26\n",
            "[100/157] loss1 = 0.5310, time elapsed = 0.28\n",
            "[100/157] loss2 = 0.0654, time elapsed = 0.28\n",
            "[150/157] loss1 = 0.7181, time elapsed = 0.26\n",
            "[150/157] loss2 = 0.0635, time elapsed = 0.26\n",
            "Epoch  47 >> Epoch loss1: 133.6810 , time elapsed 60.2237\n",
            "Epoch  47 >> Epoch loss2: 48.4357 , time elapsed 60.2237\n",
            "Test RMSE 1 = 4.8624, RMSE 2 = 4.7047\n",
            "[ 50/157] loss1 = 0.6667, time elapsed = 0.27\n",
            "[ 50/157] loss2 = 0.0919, time elapsed = 0.27\n",
            "[100/157] loss1 = 0.4752, time elapsed = 0.28\n",
            "[100/157] loss2 = 0.0576, time elapsed = 0.28\n",
            "[150/157] loss1 = 0.6342, time elapsed = 0.27\n",
            "[150/157] loss2 = 0.1474, time elapsed = 0.27\n",
            "Epoch  48 >> Epoch loss1: 126.6726 , time elapsed 59.6144\n",
            "Epoch  48 >> Epoch loss2: 44.6417 , time elapsed 59.6144\n",
            "Test RMSE 1 = 4.8494, RMSE 2 = 4.7284\n",
            "[ 50/157] loss1 = 0.4331, time elapsed = 0.26\n",
            "[ 50/157] loss2 = 0.0773, time elapsed = 0.26\n",
            "[100/157] loss1 = 0.5251, time elapsed = 0.29\n",
            "[100/157] loss2 = 0.0952, time elapsed = 0.29\n",
            "[150/157] loss1 = 0.5768, time elapsed = 0.27\n",
            "[150/157] loss2 = 0.1205, time elapsed = 0.27\n",
            "Epoch  49 >> Epoch loss1: 120.0294 , time elapsed 59.6308\n",
            "Epoch  49 >> Epoch loss2: 42.3628 , time elapsed 59.6308\n",
            "Test RMSE 1 = 4.8259, RMSE 2 = 4.7206\n",
            "[ 50/157] loss1 = 0.5493, time elapsed = 0.28\n",
            "[ 50/157] loss2 = 0.1005, time elapsed = 0.28\n",
            "[100/157] loss1 = 0.8737, time elapsed = 0.27\n",
            "[100/157] loss2 = 0.3503, time elapsed = 0.27\n",
            "[150/157] loss1 = 0.5592, time elapsed = 0.26\n",
            "[150/157] loss2 = 0.0752, time elapsed = 0.26\n",
            "Epoch  50 >> Epoch loss1: 116.6916 , time elapsed 59.6729\n",
            "Epoch  50 >> Epoch loss2: 42.0990 , time elapsed 59.6729\n",
            "Test RMSE 1 = 4.8161, RMSE 2 = 4.7379\n",
            "[ 50/157] loss1 = 0.6081, time elapsed = 0.28\n",
            "[ 50/157] loss2 = 0.1066, time elapsed = 0.28\n",
            "[100/157] loss1 = 0.5816, time elapsed = 0.27\n",
            "[100/157] loss2 = 0.1112, time elapsed = 0.27\n",
            "[150/157] loss1 = 0.8572, time elapsed = 0.27\n",
            "[150/157] loss2 = 0.2810, time elapsed = 0.27\n",
            "Epoch  51 >> Epoch loss1: 115.4740 , time elapsed 59.8770\n",
            "Epoch  51 >> Epoch loss2: 43.0778 , time elapsed 59.8770\n",
            "Test RMSE 1 = 4.8447, RMSE 2 = 4.7090\n",
            "[ 50/157] loss1 = 0.5284, time elapsed = 0.28\n",
            "[ 50/157] loss2 = 0.0562, time elapsed = 0.28\n",
            "[100/157] loss1 = 0.3041, time elapsed = 0.28\n",
            "[100/157] loss2 = 0.0845, time elapsed = 0.28\n",
            "[150/157] loss1 = 0.6765, time elapsed = 0.28\n",
            "[150/157] loss2 = 0.1056, time elapsed = 0.28\n",
            "Epoch  52 >> Epoch loss1: 112.3089 , time elapsed 59.6985\n",
            "Epoch  52 >> Epoch loss2: 44.6943 , time elapsed 59.6985\n",
            "Test RMSE 1 = 4.8080, RMSE 2 = 4.7069\n",
            "[ 50/157] loss1 = 0.2839, time elapsed = 0.27\n",
            "[ 50/157] loss2 = 0.0617, time elapsed = 0.27\n",
            "[100/157] loss1 = 0.5059, time elapsed = 0.27\n",
            "[100/157] loss2 = 0.0728, time elapsed = 0.27\n",
            "[150/157] loss1 = 0.4475, time elapsed = 0.26\n",
            "[150/157] loss2 = 0.0944, time elapsed = 0.26\n",
            "Epoch  53 >> Epoch loss1: 110.1335 , time elapsed 59.5752\n",
            "Epoch  53 >> Epoch loss2: 43.7464 , time elapsed 59.5752\n",
            "Test RMSE 1 = 4.7943, RMSE 2 = 4.7070\n",
            "[ 50/157] loss1 = 0.6582, time elapsed = 0.28\n",
            "[ 50/157] loss2 = 0.2971, time elapsed = 0.28\n",
            "[100/157] loss1 = 0.4516, time elapsed = 0.27\n",
            "[100/157] loss2 = 0.0561, time elapsed = 0.27\n",
            "[150/157] loss1 = 0.4443, time elapsed = 0.26\n",
            "[150/157] loss2 = 0.0507, time elapsed = 0.26\n",
            "Epoch  54 >> Epoch loss1: 101.2019 , time elapsed 59.5041\n",
            "Epoch  54 >> Epoch loss2: 40.0187 , time elapsed 59.5041\n",
            "Test RMSE 1 = 4.7764, RMSE 2 = 4.7177\n",
            "[ 50/157] loss1 = 0.4465, time elapsed = 0.30\n",
            "[ 50/157] loss2 = 0.0524, time elapsed = 0.30\n",
            "[100/157] loss1 = 0.3570, time elapsed = 0.27\n",
            "[100/157] loss2 = 0.0455, time elapsed = 0.27\n",
            "[150/157] loss1 = 0.4155, time elapsed = 0.27\n",
            "[150/157] loss2 = 0.0757, time elapsed = 0.27\n",
            "Epoch  55 >> Epoch loss1: 100.7159 , time elapsed 59.7976\n",
            "Epoch  55 >> Epoch loss2: 39.3444 , time elapsed 59.7976\n",
            "Test RMSE 1 = 4.8057, RMSE 2 = 4.7181\n",
            "[ 50/157] loss1 = 0.5823, time elapsed = 0.27\n",
            "[ 50/157] loss2 = 0.1066, time elapsed = 0.27\n",
            "[100/157] loss1 = 0.4694, time elapsed = 0.27\n",
            "[100/157] loss2 = 0.0525, time elapsed = 0.27\n",
            "[150/157] loss1 = 0.2703, time elapsed = 0.29\n",
            "[150/157] loss2 = 0.0326, time elapsed = 0.29\n",
            "Epoch  56 >> Epoch loss1: 96.1750 , time elapsed 60.0673\n",
            "Epoch  56 >> Epoch loss2: 37.0860 , time elapsed 60.0673\n",
            "Test RMSE 1 = 4.7921, RMSE 2 = 4.7046\n",
            "[ 50/157] loss1 = 0.6781, time elapsed = 0.27\n",
            "[ 50/157] loss2 = 0.2790, time elapsed = 0.27\n",
            "[100/157] loss1 = 0.8135, time elapsed = 0.27\n",
            "[100/157] loss2 = 0.3360, time elapsed = 0.27\n",
            "[150/157] loss1 = 0.3028, time elapsed = 0.27\n",
            "[150/157] loss2 = 0.0569, time elapsed = 0.27\n",
            "Epoch  57 >> Epoch loss1: 91.9268 , time elapsed 59.6693\n",
            "Epoch  57 >> Epoch loss2: 36.0797 , time elapsed 59.6693\n",
            "Test RMSE 1 = 4.7986, RMSE 2 = 4.7199\n",
            "[ 50/157] loss1 = 0.3576, time elapsed = 0.26\n",
            "[ 50/157] loss2 = 0.0477, time elapsed = 0.26\n",
            "[100/157] loss1 = 0.3524, time elapsed = 0.26\n",
            "[100/157] loss2 = 0.0570, time elapsed = 0.26\n",
            "[150/157] loss1 = 0.4985, time elapsed = 0.29\n",
            "[150/157] loss2 = 0.1259, time elapsed = 0.29\n",
            "Epoch  58 >> Epoch loss1: 94.4245 , time elapsed 59.6598\n",
            "Epoch  58 >> Epoch loss2: 40.0285 , time elapsed 59.6598\n",
            "Test RMSE 1 = 4.7876, RMSE 2 = 4.6958\n",
            "[ 50/157] loss1 = 0.3380, time elapsed = 0.26\n",
            "[ 50/157] loss2 = 0.0618, time elapsed = 0.26\n",
            "[100/157] loss1 = 0.5193, time elapsed = 0.27\n",
            "[100/157] loss2 = 0.0757, time elapsed = 0.27\n",
            "[150/157] loss1 = 0.2261, time elapsed = 0.28\n",
            "[150/157] loss2 = 0.0474, time elapsed = 0.28\n",
            "Epoch  59 >> Epoch loss1: 87.0669 , time elapsed 59.4873\n",
            "Epoch  59 >> Epoch loss2: 35.4863 , time elapsed 59.4873\n",
            "Test RMSE 1 = 4.7708, RMSE 2 = 4.7008\n",
            "[ 50/157] loss1 = 0.3479, time elapsed = 0.27\n",
            "[ 50/157] loss2 = 0.0842, time elapsed = 0.27\n",
            "[100/157] loss1 = 0.3266, time elapsed = 0.26\n",
            "[100/157] loss2 = 0.1271, time elapsed = 0.26\n",
            "[150/157] loss1 = 0.2686, time elapsed = 0.28\n",
            "[150/157] loss2 = 0.0678, time elapsed = 0.28\n",
            "Epoch  60 >> Epoch loss1: 85.6686 , time elapsed 59.6750\n",
            "Epoch  60 >> Epoch loss2: 35.6094 , time elapsed 59.6750\n",
            "Test RMSE 1 = 4.7907, RMSE 2 = 4.7083\n",
            "[ 50/157] loss1 = 0.4175, time elapsed = 0.28\n",
            "[ 50/157] loss2 = 0.0551, time elapsed = 0.28\n",
            "[100/157] loss1 = 0.2734, time elapsed = 0.27\n",
            "[100/157] loss2 = 0.0399, time elapsed = 0.27\n",
            "[150/157] loss1 = 0.2904, time elapsed = 0.28\n",
            "[150/157] loss2 = 0.0461, time elapsed = 0.28\n",
            "Epoch  61 >> Epoch loss1: 91.7036 , time elapsed 59.9948\n",
            "Epoch  61 >> Epoch loss2: 40.3141 , time elapsed 59.9948\n",
            "Test RMSE 1 = 4.7782, RMSE 2 = 4.7038\n",
            "[ 50/157] loss1 = 0.2906, time elapsed = 0.26\n",
            "[ 50/157] loss2 = 0.1020, time elapsed = 0.26\n",
            "[100/157] loss1 = 0.4870, time elapsed = 0.28\n",
            "[100/157] loss2 = 0.1414, time elapsed = 0.28\n",
            "[150/157] loss1 = 0.3416, time elapsed = 0.26\n",
            "[150/157] loss2 = 0.1063, time elapsed = 0.26\n",
            "Epoch  62 >> Epoch loss1: 91.7758 , time elapsed 59.7194\n",
            "Epoch  62 >> Epoch loss2: 42.4239 , time elapsed 59.7194\n",
            "Test RMSE 1 = 4.7752, RMSE 2 = 4.6800\n",
            "[ 50/157] loss1 = 0.3209, time elapsed = 0.26\n",
            "[ 50/157] loss2 = 0.0462, time elapsed = 0.26\n",
            "[100/157] loss1 = 0.2822, time elapsed = 0.27\n",
            "[100/157] loss2 = 0.0366, time elapsed = 0.27\n",
            "[150/157] loss1 = 0.4580, time elapsed = 0.26\n",
            "[150/157] loss2 = 0.2551, time elapsed = 0.26\n",
            "Epoch  63 >> Epoch loss1: 81.3930 , time elapsed 59.4171\n",
            "Epoch  63 >> Epoch loss2: 34.6017 , time elapsed 59.4171\n",
            "Test RMSE 1 = 4.7642, RMSE 2 = 4.6786\n",
            "[ 50/157] loss1 = 0.6281, time elapsed = 0.28\n",
            "[ 50/157] loss2 = 0.0961, time elapsed = 0.28\n",
            "[100/157] loss1 = 0.2343, time elapsed = 0.28\n",
            "[100/157] loss2 = 0.0748, time elapsed = 0.28\n",
            "[150/157] loss1 = 0.2089, time elapsed = 0.27\n",
            "[150/157] loss2 = 0.0515, time elapsed = 0.27\n",
            "Epoch  64 >> Epoch loss1: 83.2771 , time elapsed 59.3850\n",
            "Epoch  64 >> Epoch loss2: 37.4676 , time elapsed 59.3850\n",
            "Test RMSE 1 = 4.7807, RMSE 2 = 4.6966\n",
            "[ 50/157] loss1 = 0.4016, time elapsed = 0.26\n",
            "[ 50/157] loss2 = 0.0812, time elapsed = 0.26\n",
            "[100/157] loss1 = 0.3455, time elapsed = 0.27\n",
            "[100/157] loss2 = 0.0444, time elapsed = 0.27\n",
            "[150/157] loss1 = 0.4080, time elapsed = 0.27\n",
            "[150/157] loss2 = 0.0985, time elapsed = 0.27\n",
            "Epoch  65 >> Epoch loss1: 76.6972 , time elapsed 59.4564\n",
            "Epoch  65 >> Epoch loss2: 32.2045 , time elapsed 59.4564\n",
            "Test RMSE 1 = 4.7759, RMSE 2 = 4.6984\n",
            "[ 50/157] loss1 = 0.4387, time elapsed = 0.29\n",
            "[ 50/157] loss2 = 0.0614, time elapsed = 0.29\n",
            "[100/157] loss1 = 0.3988, time elapsed = 0.27\n",
            "[100/157] loss2 = 0.0975, time elapsed = 0.27\n",
            "[150/157] loss1 = 0.2586, time elapsed = 0.28\n",
            "[150/157] loss2 = 0.0424, time elapsed = 0.28\n",
            "Epoch  66 >> Epoch loss1: 80.0620 , time elapsed 60.2997\n",
            "Epoch  66 >> Epoch loss2: 36.5237 , time elapsed 60.2997\n",
            "Test RMSE 1 = 4.7662, RMSE 2 = 4.7042\n",
            "[ 50/157] loss1 = 0.3069, time elapsed = 0.28\n",
            "[ 50/157] loss2 = 0.0427, time elapsed = 0.28\n",
            "[100/157] loss1 = 0.3007, time elapsed = 0.27\n",
            "[100/157] loss2 = 0.0582, time elapsed = 0.27\n",
            "[150/157] loss1 = 0.3401, time elapsed = 0.26\n",
            "[150/157] loss2 = 0.0637, time elapsed = 0.26\n",
            "Epoch  67 >> Epoch loss1: 69.3002 , time elapsed 59.4464\n",
            "Epoch  67 >> Epoch loss2: 29.2227 , time elapsed 59.4464\n",
            "Test RMSE 1 = 4.7511, RMSE 2 = 4.6954\n",
            "[ 50/157] loss1 = 0.2795, time elapsed = 0.27\n",
            "[ 50/157] loss2 = 0.0396, time elapsed = 0.27\n",
            "[100/157] loss1 = 0.2363, time elapsed = 0.26\n",
            "[100/157] loss2 = 0.0355, time elapsed = 0.26\n",
            "[150/157] loss1 = 0.2578, time elapsed = 0.27\n",
            "[150/157] loss2 = 0.0382, time elapsed = 0.27\n",
            "Epoch  68 >> Epoch loss1: 77.3689 , time elapsed 59.8186\n",
            "Epoch  68 >> Epoch loss2: 36.3307 , time elapsed 59.8186\n",
            "Test RMSE 1 = 4.7603, RMSE 2 = 4.6746\n",
            "[ 50/157] loss1 = 0.3044, time elapsed = 0.26\n",
            "[ 50/157] loss2 = 0.0481, time elapsed = 0.26\n",
            "[100/157] loss1 = 0.1363, time elapsed = 0.27\n",
            "[100/157] loss2 = 0.0251, time elapsed = 0.27\n",
            "[150/157] loss1 = 0.2900, time elapsed = 0.27\n",
            "[150/157] loss2 = 0.0352, time elapsed = 0.27\n",
            "Epoch  69 >> Epoch loss1: 78.5208 , time elapsed 59.3584\n",
            "Epoch  69 >> Epoch loss2: 37.6383 , time elapsed 59.3584\n",
            "Test RMSE 1 = 4.7418, RMSE 2 = 4.6633\n",
            "[ 50/157] loss1 = 0.2885, time elapsed = 0.27\n",
            "[ 50/157] loss2 = 0.0323, time elapsed = 0.27\n",
            "[100/157] loss1 = 0.2301, time elapsed = 0.27\n",
            "[100/157] loss2 = 0.0465, time elapsed = 0.27\n",
            "[150/157] loss1 = 0.2668, time elapsed = 0.29\n",
            "[150/157] loss2 = 0.0623, time elapsed = 0.29\n",
            "Epoch  70 >> Epoch loss1: 72.9507 , time elapsed 59.9310\n",
            "Epoch  70 >> Epoch loss2: 34.5780 , time elapsed 59.9310\n",
            "Test RMSE 1 = 4.7392, RMSE 2 = 4.6815\n",
            "[ 50/157] loss1 = 0.4260, time elapsed = 0.27\n",
            "[ 50/157] loss2 = 0.1119, time elapsed = 0.27\n",
            "[100/157] loss1 = 0.1395, time elapsed = 0.29\n",
            "[100/157] loss2 = 0.0381, time elapsed = 0.29\n",
            "[150/157] loss1 = 0.2527, time elapsed = 0.27\n",
            "[150/157] loss2 = 0.0534, time elapsed = 0.27\n",
            "Epoch  71 >> Epoch loss1: 73.7272 , time elapsed 59.9393\n",
            "Epoch  71 >> Epoch loss2: 36.2760 , time elapsed 59.9393\n",
            "Test RMSE 1 = 4.7495, RMSE 2 = 4.6661\n",
            "[ 50/157] loss1 = 0.2422, time elapsed = 0.26\n",
            "[ 50/157] loss2 = 0.0363, time elapsed = 0.26\n",
            "[100/157] loss1 = 0.1994, time elapsed = 0.26\n",
            "[100/157] loss2 = 0.0324, time elapsed = 0.26\n",
            "[150/157] loss1 = 0.2304, time elapsed = 0.27\n",
            "[150/157] loss2 = 0.0533, time elapsed = 0.27\n",
            "Epoch  72 >> Epoch loss1: 70.1403 , time elapsed 59.3443\n",
            "Epoch  72 >> Epoch loss2: 34.0928 , time elapsed 59.3443\n",
            "Test RMSE 1 = 4.7628, RMSE 2 = 4.6736\n",
            "[ 50/157] loss1 = 0.2444, time elapsed = 0.28\n",
            "[ 50/157] loss2 = 0.0642, time elapsed = 0.28\n",
            "[100/157] loss1 = 0.2579, time elapsed = 0.28\n",
            "[100/157] loss2 = 0.0777, time elapsed = 0.28\n",
            "[150/157] loss1 = 0.2622, time elapsed = 0.26\n",
            "[150/157] loss2 = 0.0506, time elapsed = 0.26\n",
            "Epoch  73 >> Epoch loss1: 69.3614 , time elapsed 59.4831\n",
            "Epoch  73 >> Epoch loss2: 33.4678 , time elapsed 59.4831\n",
            "Test RMSE 1 = 4.7283, RMSE 2 = 4.6687\n",
            "[ 50/157] loss1 = 0.2420, time elapsed = 0.26\n",
            "[ 50/157] loss2 = 0.0309, time elapsed = 0.26\n",
            "[100/157] loss1 = 0.1592, time elapsed = 0.28\n",
            "[100/157] loss2 = 0.0795, time elapsed = 0.28\n",
            "[150/157] loss1 = 0.2868, time elapsed = 0.26\n",
            "[150/157] loss2 = 0.0311, time elapsed = 0.26\n",
            "Epoch  74 >> Epoch loss1: 65.8063 , time elapsed 59.2305\n",
            "Epoch  74 >> Epoch loss2: 33.0085 , time elapsed 59.2305\n",
            "Test RMSE 1 = 4.7407, RMSE 2 = 4.6531\n",
            "[ 50/157] loss1 = 0.7139, time elapsed = 0.26\n",
            "[ 50/157] loss2 = 0.5816, time elapsed = 0.26\n",
            "[100/157] loss1 = 0.2988, time elapsed = 0.27\n",
            "[100/157] loss2 = 0.0658, time elapsed = 0.27\n",
            "[150/157] loss1 = 0.2833, time elapsed = 0.27\n",
            "[150/157] loss2 = 0.0491, time elapsed = 0.27\n",
            "Epoch  75 >> Epoch loss1: 67.6101 , time elapsed 59.7865\n",
            "Epoch  75 >> Epoch loss2: 33.3792 , time elapsed 59.7865\n",
            "Test RMSE 1 = 4.7478, RMSE 2 = 4.6575\n",
            "[ 50/157] loss1 = 0.5427, time elapsed = 0.28\n",
            "[ 50/157] loss2 = 0.1990, time elapsed = 0.28\n",
            "[100/157] loss1 = 0.2565, time elapsed = 0.26\n",
            "[100/157] loss2 = 0.0682, time elapsed = 0.26\n",
            "[150/157] loss1 = 0.3214, time elapsed = 0.29\n",
            "[150/157] loss2 = 0.0292, time elapsed = 0.29\n",
            "Epoch  76 >> Epoch loss1: 64.6820 , time elapsed 59.9071\n",
            "Epoch  76 >> Epoch loss2: 31.6667 , time elapsed 59.9071\n",
            "Test RMSE 1 = 4.7360, RMSE 2 = 4.6611\n",
            "[ 50/157] loss1 = 0.5675, time elapsed = 0.26\n",
            "[ 50/157] loss2 = 0.3395, time elapsed = 0.26\n",
            "[100/157] loss1 = 0.3225, time elapsed = 0.27\n",
            "[100/157] loss2 = 0.1043, time elapsed = 0.27\n",
            "[150/157] loss1 = 0.1239, time elapsed = 0.28\n",
            "[150/157] loss2 = 0.0255, time elapsed = 0.28\n",
            "Epoch  77 >> Epoch loss1: 63.5030 , time elapsed 59.3903\n",
            "Epoch  77 >> Epoch loss2: 31.8660 , time elapsed 59.3903\n",
            "Test RMSE 1 = 4.7208, RMSE 2 = 4.6646\n",
            "[ 50/157] loss1 = 0.2311, time elapsed = 0.28\n",
            "[ 50/157] loss2 = 0.0359, time elapsed = 0.28\n",
            "[100/157] loss1 = 0.2175, time elapsed = 0.27\n",
            "[100/157] loss2 = 0.0920, time elapsed = 0.27\n",
            "[150/157] loss1 = 0.2823, time elapsed = 0.28\n",
            "[150/157] loss2 = 0.0942, time elapsed = 0.28\n",
            "Epoch  78 >> Epoch loss1: 66.8747 , time elapsed 59.7620\n",
            "Epoch  78 >> Epoch loss2: 34.1127 , time elapsed 59.7620\n",
            "Test RMSE 1 = 4.7196, RMSE 2 = 4.6637\n",
            "[ 50/157] loss1 = 0.1558, time elapsed = 0.27\n",
            "[ 50/157] loss2 = 0.0180, time elapsed = 0.27\n",
            "[100/157] loss1 = 0.1436, time elapsed = 0.27\n",
            "[100/157] loss2 = 0.0756, time elapsed = 0.27\n",
            "[150/157] loss1 = 0.1778, time elapsed = 0.27\n",
            "[150/157] loss2 = 0.0301, time elapsed = 0.27\n",
            "Epoch  79 >> Epoch loss1: 65.5856 , time elapsed 59.6535\n",
            "Epoch  79 >> Epoch loss2: 35.5279 , time elapsed 59.6535\n",
            "Test RMSE 1 = 4.7233, RMSE 2 = 4.6385\n",
            "[ 50/157] loss1 = 0.1484, time elapsed = 0.55\n",
            "[ 50/157] loss2 = 0.0273, time elapsed = 0.55\n",
            "[100/157] loss1 = 0.1933, time elapsed = 0.55\n",
            "[100/157] loss2 = 0.0424, time elapsed = 0.55\n",
            "[150/157] loss1 = 0.0980, time elapsed = 0.54\n",
            "[150/157] loss2 = 0.0258, time elapsed = 0.54\n",
            "Epoch  80 >> Epoch loss1: 64.4918 , time elapsed 124.2877\n",
            "Epoch  80 >> Epoch loss2: 34.9555 , time elapsed 124.2877\n",
            "Test RMSE 1 = 4.7342, RMSE 2 = 4.6459\n",
            "[ 50/157] loss1 = 0.2181, time elapsed = 0.62\n",
            "[ 50/157] loss2 = 0.0396, time elapsed = 0.62\n",
            "[100/157] loss1 = 0.1723, time elapsed = 0.59\n",
            "[100/157] loss2 = 0.0359, time elapsed = 0.59\n",
            "[150/157] loss1 = 0.2693, time elapsed = 0.48\n",
            "[150/157] loss2 = 0.0352, time elapsed = 0.48\n",
            "Epoch  81 >> Epoch loss1: 60.8576 , time elapsed 138.6539\n",
            "Epoch  81 >> Epoch loss2: 29.7866 , time elapsed 138.6539\n",
            "Test RMSE 1 = 4.7093, RMSE 2 = 4.6443\n",
            "[ 50/157] loss1 = 0.1111, time elapsed = 0.58\n",
            "[ 50/157] loss2 = 0.0269, time elapsed = 0.58\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-00e64ce7b284>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m# train_op: train, optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m# loss : batch loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_op_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss_1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_op_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss_2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0melapsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1173\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1350\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1354\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1339\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1341\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1427\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnstWfUHWyo3",
        "colab_type": "code",
        "outputId": "fdbf9431-8c93-454e-c4c5-54cebf0ac762",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print('Best RMSE is %.4f at EPOCH %d' % (best_rmse, best_epoch))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best RMSE is 4.6385 at EPOCH 79\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HFc7tSXFJdp",
        "colab_type": "code",
        "outputId": "edf06e9c-a895-4d03-8c0a-aea8ee261da8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Jul 25 02:35:35 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 418.67       Driver Version: 410.79       CUDA Version: 10.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P8    24W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMkv4U2G_c59",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}