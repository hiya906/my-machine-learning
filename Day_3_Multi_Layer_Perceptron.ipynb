{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Day 3. Multi Layer Perceptron",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "1VYgEnGydVMz",
        "jB-xeLYze94b"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hiya906/my-machine-learning/blob/master/Day_3_Multi_Layer_Perceptron.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byJzQYggCxfU",
        "colab_type": "text"
      },
      "source": [
        "#사용법\n",
        "\n",
        "1. 우측 상단 '로그인'\n",
        "\n",
        "2. 좌측 상단 '실습 모드에서 열기'\n",
        "\n",
        "※ 각각의 셀은 셀 좌측 상단 실행 버튼을 통해 실행할 수 있습니다.\n",
        "\n",
        "※ 실행 중 '경고: 이 노트는 Google에서 작성하지 않았습니다.'라는 창이 뜰 경우, '실행 전에 모든 런타임 재설정'란에 체크 후 '무시하고 계속하기'를 하시면 됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDibQ6yNcjGw",
        "colab_type": "text"
      },
      "source": [
        "# 1. MLP 실습 - XOR 연산"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhhidmAgc-Z0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "outputId": "121e93e9-ded1-498c-aa01-d9872d7130c0"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf # 입력과 정답 구성\n",
        "\n",
        "\n",
        "X = tf.placeholder(tf.float32, [None, 2], name=\"X\") # 입력\n",
        "Y = tf.placeholder(tf.float32, [None, 1], name=\"Y\") # 정답\n",
        "\n",
        "# 파라미터 세팅\n",
        "# W1, W2 랜덤 초기화\n",
        "# b1, b2 0으로 초기화\n",
        "W1 = tf.Variable(name=\"E1_W1\", initial_value=tf.random_normal([2, 2]))\n",
        "b1 = tf.Variable(name=\"E1_b1\", initial_value=tf.zeros([2]))\n",
        "\n",
        "W2 = tf.Variable(name=\"E1_W2\", initial_value=tf.random_normal([2, 1]))\n",
        "b2 = tf.Variable(name=\"E1_b2\", initial_value=tf.zeros([1]))\n",
        "\n",
        "# 모델 만들기\n",
        "Z1 = tf.matmul(X, W1) + b1\n",
        "H = tf.sigmoid(Z1)\n",
        "\n",
        "Z2 = tf.matmul(H, W2) + b2\n",
        "Y_ = tf.sigmoid(Z2)\n",
        "\n",
        "# loss 설정\n",
        "Ln = 0.5 * tf.reduce_sum(tf.square(Y - Y_), axis=1)\n",
        "L = tf.reduce_sum(Ln)\n",
        "\n",
        "# 모델 학습 설정\n",
        "learn_rate = 0.4\n",
        "optimize = tf.train.GradientDescentOptimizer(learn_rate).minimize(L)\n",
        "\n",
        "# 세션 생성\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "\n",
        "\n",
        "# 데이터 생성\n",
        "X_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "Y_data = np.array([[0], [1], [1], [0]])\n",
        "\n",
        "# 학습\n",
        "for i in range(5000):\n",
        "    _, loss = sess.run([optimize, L],\n",
        "                       feed_dict={X: X_data, Y: Y_data})\n",
        "    if i % 200 == 0:\n",
        "        print(i, \"loss=\", loss)\n",
        "\n",
        "# 결과\n",
        "output = sess.run(Y_, feed_dict={X: X_data})\n",
        "print(\"input:\", X_data)\n",
        "print(\"output:\", output)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 loss= 0.6708171\n",
            "200 loss= 0.472042\n",
            "400 loss= 0.26691508\n",
            "600 loss= 0.069855444\n",
            "800 loss= 0.030151587\n",
            "1000 loss= 0.017963326\n",
            "1200 loss= 0.012479959\n",
            "1400 loss= 0.009449029\n",
            "1600 loss= 0.007552428\n",
            "1800 loss= 0.0062640468\n",
            "2000 loss= 0.00533644\n",
            "2200 loss= 0.0046390886\n",
            "2400 loss= 0.0040970445\n",
            "2600 loss= 0.003664426\n",
            "2800 loss= 0.003311612\n",
            "3000 loss= 0.0030187347\n",
            "3200 loss= 0.002771925\n",
            "3400 loss= 0.0025612605\n",
            "3600 loss= 0.0023794458\n",
            "3800 loss= 0.0022210183\n",
            "4000 loss= 0.0020817965\n",
            "4200 loss= 0.001958534\n",
            "4400 loss= 0.0018486688\n",
            "4600 loss= 0.0017501549\n",
            "4800 loss= 0.0016613472\n",
            "input: [[0 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 1]]\n",
            "output: [[0.02834004]\n",
            " [0.96782994]\n",
            " [0.97359574]\n",
            " [0.02503058]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6tRvl3tdNQD",
        "colab_type": "text"
      },
      "source": [
        "# 2. MLP 실습 - MLP vs Linear Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0R4UaLdDdvwj",
        "colab_type": "text"
      },
      "source": [
        "## class MLP - 코드 작성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-6L14AXduwz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class MLP_2:\n",
        "    def __init__(self, num_features):\n",
        "        ## 하이퍼 파라미터\n",
        "        self.num_hidden = 4\n",
        "        self.num_epochs = 2000\n",
        "        self.learning_rate = 0.05\n",
        "\n",
        "        ## 학습 파라미터 정의\n",
        "        # self.W1 =\n",
        "        # self.b1 =\n",
        "        # self.W2 =\n",
        "        # self.b2 =\n",
        "\n",
        "        ## Placeholder 정의 \n",
        "        # self.X =\n",
        "        # self.Y =\n",
        "\n",
        "    def train(self, train_x, train_y):\n",
        "        ## 모델 만들기\n",
        "        # self.Y_ =\n",
        "\n",
        "        ## loss 설정\n",
        "        # cost =\n",
        "\n",
        "        ## 모델 학습 설정\n",
        "        # optimize =\n",
        "\n",
        "        # 세션 생성\n",
        "        self.sess = tf.Session()\n",
        "        self.sess.run(tf.global_variables_initializer())\n",
        "\n",
        "        # 학습\n",
        "        for i in range(self.num_epochs):\n",
        "            ###\n",
        "\n",
        "    def predict(self, test_x):\n",
        "        ## 모델 예측\n",
        "        # pred = \n",
        "        # return pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VYgEnGydVMz",
        "colab_type": "text"
      },
      "source": [
        "## class MLP - 정답 코드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6Fc-zFhdbg0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class MLP_2:\n",
        "    def __init__(self, num_features):\n",
        "        self.num_hidden = 4\n",
        "        self.num_epochs = 2000\n",
        "        self.learning_rate = 0.05\n",
        "\n",
        "        self.W1 = tf.Variable(name=\"E2_W1\", initial_value=tf.random_normal([num_features, self.num_hidden]))\n",
        "        self.b1 = tf.Variable(name=\"E2_b1\", initial_value=tf.zeros([self.num_hidden]))\n",
        "        self.W2 = tf.Variable(name=\"E2_W2\", initial_value=tf.random_normal([self.num_hidden, 1]))\n",
        "        self.b2 = tf.Variable(name=\"E2_b2\", initial_value=tf.zeros([1]))\n",
        "\n",
        "        self.X = tf.placeholder(tf.float32, [None, num_features], name=\"X\")  # 입력\n",
        "        self.Y = tf.placeholder(tf.float32, [None, 1], name=\"Y\") # 정답\n",
        "\n",
        "    def train(self, train_x, train_y):\n",
        "        # 모델 만들기\n",
        "        Z1 = tf.matmul(self.X, self.W1) + self.b1\n",
        "        H1 = tf.sigmoid(Z1)\n",
        "        Z2 = tf.matmul(H1, self.W2) + self.b2\n",
        "        self.Y_ = tf.sigmoid(Z2)\n",
        "        # Liniear Regression 하려면 바로 위에 주석처리하고 아래 코드 추가\n",
        "        #self.Y_ = tf.sigmoid(Z1) \n",
        "\n",
        "        # loss 설정\n",
        "        Ln = 0.5 * tf.reduce_sum(tf.square(self.Y - self.Y_), axis=1)\n",
        "        cost = tf.reduce_sum(Ln)\n",
        "\n",
        "        # 모델 학습 설정\n",
        "        optimize = tf.train.GradientDescentOptimizer(self.learning_rate).minimize(cost)\n",
        "\n",
        "        # 세션 생성\n",
        "        self.sess = tf.Session()\n",
        "        self.sess.run(tf.global_variables_initializer())\n",
        "\n",
        "        # 학습\n",
        "        for i in range(self.num_epochs):\n",
        "            _, L = self.sess.run([optimize, cost], feed_dict={self.X: train_x, self.Y: train_y})\n",
        "            if i % 100 == 0:\n",
        "                print(\"Step:\", i, \"Loss:\", L)\n",
        "\n",
        "    def predict(self, test_x):\n",
        "        pred = self.sess.run(self.Y_, feed_dict={self.X: test_x})\n",
        "        return pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4gkW83ideNL",
        "colab_type": "text"
      },
      "source": [
        "## 데이터 생성 및 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqnPYGD0dgtf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "outputId": "98af33c5-f67f-4ea0-d2a3-c5138c0d836f"
      },
      "source": [
        "train_x = np.sort(np.random.rand(100)) # [0,1] 범위 내의 실수 100개\n",
        "train_y = np.sin(train_x * np.pi)      # y = sin(pi * x)\n",
        "train_x = np.expand_dims(train_x,1)\n",
        "train_y = np.expand_dims(train_y,1)\n",
        "\n",
        "test_x = np.sort(np.random.rand(100))  # [0,1] 범위 내의 실수 100개\n",
        "test_y = np.sin(test_x * np.pi)        # y = sin(pi * x)\n",
        "test_x = np.expand_dims(test_x,1)\n",
        "test_y = np.expand_dims(test_y,1)\n",
        "\n",
        "num_data, num_features = train_x.shape\n",
        "print(num_data, num_features)\n",
        "\n",
        "model = MLP_2(num_features)\n",
        "model.train(train_x, train_y)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100 1\n",
            "Step: 0 Loss: 4.5521235\n",
            "Step: 100 Loss: 4.407099\n",
            "Step: 200 Loss: 4.3885064\n",
            "Step: 300 Loss: 4.3639555\n",
            "Step: 400 Loss: 4.319541\n",
            "Step: 500 Loss: 4.237088\n",
            "Step: 600 Loss: 4.088516\n",
            "Step: 700 Loss: 3.8286867\n",
            "Step: 800 Loss: 3.4167948\n",
            "Step: 900 Loss: 2.8032749\n",
            "Step: 1000 Loss: 1.9365058\n",
            "Step: 1100 Loss: 1.0897709\n",
            "Step: 1200 Loss: 0.5802235\n",
            "Step: 1300 Loss: 0.33513895\n",
            "Step: 1400 Loss: 0.21738392\n",
            "Step: 1500 Loss: 0.15661839\n",
            "Step: 1600 Loss: 0.12273223\n",
            "Step: 1700 Loss: 0.102535404\n",
            "Step: 1800 Loss: 0.08983602\n",
            "Step: 1900 Loss: 0.08150367\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaWJB81adjUL",
        "colab_type": "text"
      },
      "source": [
        "## 학습 Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNozHBX_dmDT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "dc99f8a7-782a-420f-c456-cd34316bfe7e"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "plt.scatter(test_x, test_y, label=\"train_data\")\n",
        "plt.plot(test_x, model.predict(test_x), 'r-', label=\"model\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkT0FJ0weqEE",
        "colab_type": "text"
      },
      "source": [
        "# 3. MLP 실습 - Iris 분류"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udR870Eje3wz",
        "colab_type": "text"
      },
      "source": [
        "## class MLP - 코드 작성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIfPUiD-e4zM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class MLP_3:\n",
        "    def __init__(self, num_features, num_output):\n",
        "        ## 하이퍼 파라미터\n",
        "        self.num_hidden = 4\n",
        "        self.num_epochs = 2000\n",
        "        self.learning_rate = 0.2\n",
        "\n",
        "        ## 학습 파라미터 정의\n",
        "        # self.W1 =\n",
        "        # self.b1 =\n",
        "        # self.W2 =\n",
        "        # self.b2 =\n",
        "        self.W1 = tf.Variable(name=\"E3_W1\", initial_value=tf.random_normal([num_features, self.num_hidden]))\n",
        "        self.b1 = tf.Variable(name(\"E3_b1\", initial_value=tf.zeros[self.num_hidden]))\n",
        "        self.W2 = tf.Variable(name=\"E3_W2\", initial_value=tf.random_normal([self.num_hidden, num_output]))\n",
        "        self_b2 = tf.Variable(name=\"E3_b2\", initial_value=tf.zeros[num_output])\n",
        "\n",
        "        ## Placeholder 정의 \n",
        "        # self.X =\n",
        "        # self.Y =\n",
        "        self.X = tf.placeholder(tf.float32, [None, num_features], name=\"X\")\n",
        "        self.Y = tf.placeholder(tf.float32, [None, num_output], name=\"Y\")\n",
        "\n",
        "    def train(self, train_x, train_y):\n",
        "        ## 모델 만들기\n",
        "        # self.Y_ =\n",
        "        Z1 = tf.matmul(self.X, self.W1) + self.b1\n",
        "        H1 = tf.sigmoid(Z1)\n",
        "        Z2 = tf.matmul(H1, self.W2) + self.b2\n",
        "        self.Y_ = tf.sigmoid(Z2)\n",
        "\n",
        "        # Logistic Regression Loss 설정\n",
        "        Ln = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=self.Y_, labels=self.Y))\n",
        "        cost = tf.train.GradientDescentOptimizer(self.learning_rate).minimize(cost)\n",
        "\n",
        "        ## 모델 학습 설정\n",
        "        # optimize =\n",
        "        optimize = tf.train.\n",
        "\n",
        "        # 세션 생성\n",
        "        self.sess = tf.Session()\n",
        "        self.sess.run(tf.global_variables_initializer())\n",
        "\n",
        "        # 학습\n",
        "        for i in range(self.num_epochs):\n",
        "            ###\n",
        "\n",
        "    def predict(self, test_x):\n",
        "        pred = self.sess.run(self.Y_, feed_dict={self.X: test_x})\n",
        "        predict_labels = np.argmax(pred, axis=1)\n",
        "        return predict_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jB-xeLYze94b",
        "colab_type": "text"
      },
      "source": [
        "## class MLP - 정답 코드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGhq-W0EfBk7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class MLP_3:\n",
        "    def __init__(self, num_features, num_output):\n",
        "        self.num_hidden = 4\n",
        "        self.num_epochs = 2000\n",
        "        self.learning_rate = 0.2\n",
        "\n",
        "        self.W1 = tf.Variable(name=\"E3_W1\", initial_value=tf.random_normal([num_features, self.num_hidden]))\n",
        "        self.b1 = tf.Variable(name=\"E3_b1\", initial_value=tf.zeros([self.num_hidden]))\n",
        "        self.W2 = tf.Variable(name=\"E3_W2\", initial_value=tf.random_normal([self.num_hidden, num_output]))\n",
        "        self.b2 = tf.Variable(name=\"E3_b2\", initial_value=tf.zeros([num_output]))\n",
        "\n",
        "        self.X = tf.placeholder(tf.float32, [None, num_features], name=\"X\")  # 입력\n",
        "        self.Y = tf.placeholder(tf.float32, [None, num_output], name=\"Y\") # 정답\n",
        "\n",
        "    def train(self, train_x, train_y):\n",
        "        # 모델 만들기\n",
        "        Z1 = tf.matmul(self.X, self.W1) + self.b1\n",
        "        H1 = tf.sigmoid(Z1)\n",
        "        Z2 = tf.matmul(H1, self.W2) + self.b2\n",
        "        self.Y_ = tf.sigmoid(Z2)\n",
        "\n",
        "        # Logistic Regression Loss 설정\n",
        "        Ln = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=self.Y_, labels=self.Y))\n",
        "        cost = tf.reduce_sum(Ln)\n",
        "\n",
        "        # 모델 학습 설정\n",
        "        optimize = tf.train.GradientDescentOptimizer(self.learning_rate).minimize(cost)\n",
        "\n",
        "        # 세션 생성\n",
        "        self.sess = tf.Session()\n",
        "        self.sess.run(tf.global_variables_initializer())\n",
        "\n",
        "        # 학습\n",
        "        for i in range(self.num_epochs):\n",
        "            _, L = self.sess.run([optimize, cost], feed_dict={self.X: train_x, self.Y: train_y})\n",
        "            if i % 100 == 0:\n",
        "                print(\"Step:\", i, \"Loss:\", L)\n",
        "\n",
        "    def predict(self, test_x):\n",
        "        pred = self.sess.run(self.Y_, feed_dict={self.X: test_x})\n",
        "        predict_labels = np.argmax(pred, axis=1)\n",
        "        return predict_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOZHav0skyTq",
        "colab_type": "text"
      },
      "source": [
        "## CSV 파일 읽기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNxaDJsCk4NJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "import os\n",
        "\n",
        "\n",
        "def Iris_Dataset(path, filename):\n",
        "    file = os.path.join(path, filename)\n",
        "\n",
        "    with open(file, 'r') as f:\n",
        "        csv_reader = csv.reader(f)\n",
        "        header = next(csv_reader)\n",
        "\n",
        "        x_data = []\n",
        "        y_data = []\n",
        "        for line in csv_reader:\n",
        "            x = []\n",
        "            features = line[:-1]\n",
        "            for feat in features:\n",
        "                x.append(float(feat))\n",
        "            if line[-1] == 'Iris-setosa': y = 0\n",
        "            elif line[-1] == 'Iris-versicolor': y = 1\n",
        "            else: y = 2     # 'Iris-virginica'\n",
        "            x_data.append(x)\n",
        "            y_data.append(y)\n",
        "        x_array = np.array(x_data)\n",
        "        y_array = np.array(y_data)\n",
        "\n",
        "        return header, x_array, y_array"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqK1fp9KkW5c",
        "colab_type": "text"
      },
      "source": [
        "## 데이터 생성, 학습 및 평가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGKEKgeJkbGS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "outputId": "8f2fbecb-ef52-4c5b-bb92-833243f0dd3f"
      },
      "source": [
        "# train 데이터를 읽기\n",
        "header, train_x, train_y = Iris_Dataset('./sample_data', 'Iris_train.csv')\n",
        "num_data, num_features = train_x.shape\n",
        "\n",
        "num_classes = 3     # 데이터에서 총 3가지의 품종이 제시됨\n",
        "print(train_x.shape)\n",
        "print(train_y.shape)\n",
        "\n",
        "label_y = np.eye(num_classes)[train_y]    # logistic regression을 위한 정답 label 생성\n",
        "\n",
        "# 모델 생성 및 학습\n",
        "model = MLP_3(num_features, num_classes)\n",
        "model.train(train_x, label_y)\n",
        "\n",
        "# test 데이터 읽기\n",
        "header, test_x, test_y = Iris_Dataset('./sample_data', 'Iris_test.csv')\n",
        "\n",
        "# 모델 예측 후 평가\n",
        "predict_labels = model.predict(test_x)\n",
        "accuracy = np.mean(np.equal(predict_labels, test_y))\n",
        "print(\"accuracy=\", accuracy)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(120, 4)\n",
            "(120,)\n",
            "Step: 0 Loss: 1.0896344\n",
            "Step: 100 Loss: 0.9696787\n",
            "Step: 200 Loss: 0.9104327\n",
            "Step: 300 Loss: 0.87359124\n",
            "Step: 400 Loss: 0.8493613\n",
            "Step: 500 Loss: 0.8325212\n",
            "Step: 600 Loss: 0.8203114\n",
            "Step: 700 Loss: 0.8111616\n",
            "Step: 800 Loss: 0.8041096\n",
            "Step: 900 Loss: 0.79853123\n",
            "Step: 1000 Loss: 0.7939934\n",
            "Step: 1100 Loss: 0.79014516\n",
            "Step: 1200 Loss: 0.7865226\n",
            "Step: 1300 Loss: 0.78222823\n",
            "Step: 1400 Loss: 0.7770557\n",
            "Step: 1500 Loss: 0.7716724\n",
            "Step: 1600 Loss: 0.76633275\n",
            "Step: 1700 Loss: 0.76112556\n",
            "Step: 1800 Loss: 0.75610566\n",
            "Step: 1900 Loss: 0.7513113\n",
            "accuracy= 0.6666666666666666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLYK3wXa9b0I",
        "colab_type": "text"
      },
      "source": [
        "# 4. MLP 실습 - 손글씨 분류"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OC47HIQY9kNG",
        "colab_type": "text"
      },
      "source": [
        "## class MLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbEOPzWf9mJ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "\n",
        "class MLP_4:\n",
        "    def __init__(self, num_features):\n",
        "        # 하이퍼 파라미터 설정\n",
        "        self.n_input = num_features  # input 이미지의 차원 (28*28 = 784)\n",
        "        self.n_hidden_1 = 256  # hidden layer1의 뉴런 수\n",
        "        self.n_hidden_2 = 400  # hidden layer2의 뉴런 수\n",
        "        self.n_classes = 10  # output 손글씨 분류 수 (0-9 digits)\n",
        "        self.learning_rate = 0.001\n",
        "        self.training_epochs = 10\n",
        "        self.batch_size = 100\n",
        "\n",
        "        # 파라미터 세팅\n",
        "        # W1, W2, W3 xavier 초기화 / b1, b2, b3 0으로 초기화\n",
        "        self.W1 = tf.Variable(name=\"W1\", initial_value=tf.contrib.layers.xavier_initializer()([self.n_input, self.n_hidden_1]))\n",
        "        self.b1 = tf.Variable(name=\"b1\", initial_value=tf.zeros([self.n_hidden_1]))\n",
        "        self.W2 = tf.Variable(name=\"W2\", initial_value=tf.contrib.layers.xavier_initializer()([self.n_hidden_1, self.n_hidden_2]))\n",
        "        self.b2 = tf.Variable(name=\"b2\", initial_value=tf.zeros([self.n_hidden_2]))\n",
        "        self.W3 = tf.Variable(name=\"W3\", initial_value=tf.contrib.layers.xavier_initializer()([self.n_hidden_2, self.n_classes]))\n",
        "        self.b3 = tf.Variable(name=\"b3\", initial_value=tf.zeros([self.n_classes]))\n",
        "\n",
        "        #  입력/정답 설정\n",
        "        self.X = tf.placeholder(\"float\", [None, self.n_input]) # 입력\n",
        "        self.Y = tf.placeholder(\"float\", [None, self.n_classes]) # 정답\n",
        "\n",
        "    def train(self):\n",
        "        # 모델 만들기\n",
        "        hidden_layer_1 = tf.nn.relu(tf.matmul(self.X, self.W1) + self.b1)\n",
        "        hidden_layer_2 = tf.nn.relu(tf.matmul(hidden_layer_1, self.W2) + self.b2)\n",
        "        \n",
        "        # leaky_relu\n",
        "        #hidden_layer_1 = tf.nn.leaky_relu(tf.matmul(self.X, self.W1) + self.b1)\n",
        "        #hidden_layer_2 = tf.nn.leaky_relu(tf.matmul(hidden_layer_1, self.W2) + self.b2)\n",
        "        \n",
        "        # elu\n",
        "        #hidden_layer_1 = tf.nn.elu(tf.matmul(self.X, self.W1) + self.b1)\n",
        "        #hidden_layer_2 = tf.nn.elu(tf.matmul(hidden_layer_1, self.W2) + self.b2)\n",
        "        self.output = tf.matmul(hidden_layer_2, self.W3) + self.b3\n",
        "\n",
        "        #loss 설정\n",
        "        L = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=self.output, labels=self.Y))\n",
        "        optimize = tf.train.AdamOptimizer(self.learning_rate).minimize(L) # 모델 학습 설정\n",
        "        #optimize = tf.train.GradientDescentOptimizer(self.learning_rate).minimize(L)\n",
        "\n",
        "        # 세선 생성 및 파라미터 초기화\n",
        "        self.sess = tf.Session()\n",
        "        self.sess.run(tf.global_variables_initializer())\n",
        "\n",
        "        # train data를 이용하여 batch단위로 학습\n",
        "        for epoch in range(self.training_epochs):\n",
        "            avg_loss = 0\n",
        "            total_batch = int(mnist.train.num_examples/self.batch_size)\n",
        "            # batch단위 학습\n",
        "            for i in range(total_batch):\n",
        "                # batch 크기 만큼 데이터 가져오기\n",
        "                batch_x, batch_y = mnist.train.next_batch(self.batch_size)\n",
        "                # optimization\n",
        "                _, loss = self.sess.run([optimize, L], feed_dict={self.X: batch_x, self.Y: batch_y})\n",
        "                # 평균 loss 구하기\n",
        "                avg_loss += loss / total_batch\n",
        "            print(epoch, \"loss=\", avg_loss)\n",
        "\n",
        "    def predict(self, test_x):\n",
        "        pred = self.sess.run(self.output, feed_dict={self.X: test_x})\n",
        "        predict_labels = np.argmax(pred, axis=1)\n",
        "        return predict_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1KxZnKg91bF",
        "colab_type": "text"
      },
      "source": [
        "## 데이터 생성, 학습 및 평가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6coCKOVP93_1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "420a5236-53e1-4bb2-9c88-dcf0e60b26a1"
      },
      "source": [
        "# 손글씨 데이터 셋 불러오기\n",
        "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
        "\n",
        "# 모델 생성 및 학습\n",
        "model = MLP_4(784)\n",
        "model.train()\n",
        "\n",
        "predict_labels = model.predict(mnist.test.images)  # 모델의 예측 label\n",
        "true_labels = np.argmax(mnist.test.labels, axis=1) # 실제 label\n",
        "\n",
        "# accuracy 계산\n",
        "accuracy = np.mean(np.equal(predict_labels, true_labels))\n",
        "print(\"accuracy=\", accuracy)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
            "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
            "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
            "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
            "0 loss= 0.24963611076501266\n",
            "1 loss= 0.09546647367152306\n",
            "2 loss= 0.06408249240876598\n",
            "3 loss= 0.043512043785727185\n",
            "4 loss= 0.03385445896641946\n",
            "5 loss= 0.027076900225259676\n",
            "6 loss= 0.023381690287179385\n",
            "7 loss= 0.01665810584503396\n",
            "8 loss= 0.014530226461144841\n",
            "9 loss= 0.01654044471085813\n",
            "accuracy= 0.9782\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wbN4ICo97eO",
        "colab_type": "text"
      },
      "source": [
        "## 이미지 별 예측 결과 직접 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFBy4TmC9_59",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "43397722-78a3-4df8-ced7-0364de6d3319"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# 손글씨 이미지와 예측 결과 살펴보기\n",
        "plt.figure()\n",
        "check_data = 30\n",
        "# 예측 label 출력\n",
        "print(\"predicted label=\", predict_labels[check_data])\n",
        "\n",
        "image = np.reshape(mnist.test.images[check_data], [28, 28]) # 이미지 만들기\n",
        "plt.imshow(image, cmap='Greys')\n",
        "plt.show() # 이미지 출력"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predicted label= 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nivADQRF+IKj/AbceYAMJJwoUAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x37UGHBJ0C7q",
        "colab_type": "text"
      },
      "source": [
        "# 5. MLP 실습 - 의류 데이터 분류"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35PVeCgW0GId",
        "colab_type": "text"
      },
      "source": [
        "## class MLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plIrUeMR0Ix1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "def get_l2(param):\n",
        "  regu = 0\n",
        "  for p in param:\n",
        "    regu += tf.nn.l2_loss(p)\n",
        "  return regu\n",
        "\n",
        "class MLP_5:\n",
        "    def __init__(self, num_features, num_classes):\n",
        "        # 하이퍼 파라미터 설정\n",
        "        self.n_input = num_features  # input 이미지의 차원 (28*28 = 784)\n",
        "        self.n_hidden_1 = 350  # hidden layer1의 뉴런 수\n",
        "        self.n_hidden_2 = 350  # hidden layer2의 뉴런 수\n",
        "        self.n_classes = num_classes  # output 손글씨 분류 수 (0-9 digits)\n",
        "        self.learning_rate = 0.001\n",
        "        self.training_epochs = 10\n",
        "        self.batch_size = 100\n",
        "        self.regularization_term = 0.001\n",
        "\n",
        "        # 파라미터 세팅\n",
        "        # W1, W2, W3 xavier 초기화 / b1, b2, b3 0으로 초기화\n",
        "        self.W1 = tf.Variable(name=\"W1\", initial_value=tf.contrib.layers.xavier_initializer()([self.n_input, self.n_hidden_1]))\n",
        "        self.b1 = tf.Variable(name=\"b1\", initial_value=tf.zeros([self.n_hidden_1]))\n",
        "        self.W2 = tf.Variable(name=\"W2\", initial_value=tf.contrib.layers.xavier_initializer()([self.n_hidden_1, self.n_hidden_2]))\n",
        "        self.b2 = tf.Variable(name=\"b2\", initial_value=tf.zeros([self.n_hidden_2]))\n",
        "        self.W3 = tf.Variable(name=\"W3\", initial_value=tf.contrib.layers.xavier_initializer()([self.n_hidden_2, self.n_classes]))\n",
        "        self.b3 = tf.Variable(name=\"b3\", initial_value=tf.zeros([self.n_classes]))\n",
        "        self.params = [self.W1, self.b1, self.W2, self.b2, self.W3, self.b3]\n",
        "\n",
        "        #  입력/정답 설정\n",
        "        self.X = tf.placeholder(\"float\", [None, self.n_input]) # 입력\n",
        "        self.Y = tf.placeholder(\"float\", [None, self.n_classes]) # 정답\n",
        "\n",
        "    def train(self, train_x, train_y):\n",
        "        # 모델 만들기\n",
        "        hidden_layer_1 = tf.nn.relu(tf.matmul(self.X, self.W1) + self.b1)\n",
        "        hidden_layer_2 = tf.nn.relu(tf.matmul(hidden_layer_1, self.W2) + self.b2)\n",
        "        self.output = tf.matmul(hidden_layer_2, self.W3) + self.b3\n",
        "\n",
        "        #loss 설정\n",
        "        cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=self.output, labels=self.Y))\n",
        "        \n",
        "        #regularize\n",
        "        \n",
        "        #regu = tf.nn.l2_loss(self.W1) + tf.nn.l2_loss(self.b1) + tf.nn.l2_loss(self.W2) + tf.nn.l2_loss(self.b2) + tf.nn.l2_loss(self.W3) + tf.nn.l2_loss(self.b3)\n",
        "        regu = get_l2(self.params)\n",
        "        cost = cost + self.regularization_term * regu\n",
        "        \n",
        "        optimize = tf.train.AdamOptimizer(self.learning_rate).minimize(cost) # 모델 학습 설정\n",
        "\n",
        "        # 세선 생성 및 파라미터 초기화\n",
        "        self.sess = tf.Session()\n",
        "        self.sess.run(tf.global_variables_initializer())\n",
        "\n",
        "        # train data를 이용하여 batch 단위로 학습\n",
        "        total_data_size = train_x.shape[0]\n",
        "        for epoch in range(self.training_epochs):\n",
        "            avg_loss = 0\n",
        "\n",
        "            # 전체 데이터의 수와 분할하고자 하는 batch의 크기가 주어지면, 자동적으로 총 batch의 수가 결정된다.\n",
        "            total_batch = int((total_data_size + self.batch_size - 1)/self.batch_size)\n",
        "\n",
        "            # batch 단위 학습\n",
        "            for i in range(total_batch):\n",
        "                # batch 크기 만큼 데이터 가져오기\n",
        "                start = i * self.batch_size                         # batch의 시작 위치\n",
        "                end = min((i+1) * self.batch_size, total_data_size) # batch의 끝 위치\n",
        "                batch_x = train_x[start:end]    # 입력 batch\n",
        "                batch_y = train_y[start:end]    # 정답 batch\n",
        "                # optimization\n",
        "                _, loss = self.sess.run([optimize, cost], feed_dict={self.X: batch_x, self.Y: batch_y})\n",
        "                # 평균 loss 구하기\n",
        "                avg_loss += loss / total_batch\n",
        "            print(epoch, \"loss=\", avg_loss)\n",
        "\n",
        "    def predict(self, test_x):\n",
        "        pred = self.sess.run(self.output, feed_dict={self.X: test_x})\n",
        "        predict_labels = np.argmax(pred, axis=1)\n",
        "        return predict_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-cjHzXN0Rbi",
        "colab_type": "text"
      },
      "source": [
        "##  gzip 파일 읽기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f432qHYl0iWl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import gzip\n",
        "\n",
        "\n",
        "def load_mnist(path, kind='train'):\n",
        "\n",
        "    \"\"\"Load MNIST data from `path`\"\"\"\n",
        "    labels_path = os.path.join(path, \"%s-labels.gz\" % kind)\n",
        "    images_path = os.path.join(path, \"%s-images.gz\" % kind)\n",
        "\n",
        "    with gzip.open(labels_path, 'rb') as lbpath:\n",
        "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8, offset=8)\n",
        "\n",
        "    with gzip.open(images_path, 'rb') as imgpath:\n",
        "        images = np.frombuffer(imgpath.read(), dtype=np.uint8, offset=16).reshape(len(labels), 784)\n",
        "\n",
        "    return images, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pGCpJpC0p0h",
        "colab_type": "text"
      },
      "source": [
        "## 데이터 생성, 학습 및 평가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aC9SLYE0rzU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "25533caf-d9d4-48f1-e7da-73b05bec456e"
      },
      "source": [
        "path = \"sample_data/\"\n",
        "images_filename = path + \"train_images\"\n",
        "labels_filename = path + \"train_labels\"\n",
        "\n",
        "train_x, train_y = load_mnist(path, kind='train')\n",
        "test_x, test_y = load_mnist(path, kind='test')\n",
        "\n",
        "print(\"train_x:\", train_x.shape) # (60000, 784)\n",
        "print(\"train_y:\", train_y.shape) # (60000, )\n",
        "print(\"test_x:\", test_x.shape)   # (10000, 784)\n",
        "print(\"test_y:\", test_y.shape)   # (10000, )\n",
        "#print(train_x[0])\n",
        "\n",
        "num_features = train_x.shape[1]\n",
        "num_classes = 10\n",
        "\n",
        "# 모델 생성 및 학습\n",
        "model = MLP_5(num_features, num_classes)\n",
        "label_y = np.eye(num_classes)[train_y]    # logistic regression을 위한 정답 label 생성\n",
        "model.train(train_x, label_y)\n",
        "\n",
        "predict_labels = model.predict(test_x) # 모델의 예측 label\n",
        "\n",
        "# accuracy 계산\n",
        "accuracy = np.mean(np.equal(predict_labels, test_y))\n",
        "print(\"accuracy=\", accuracy)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_x: (60000, 784)\n",
            "train_y: (60000,)\n",
            "test_x: (10000, 784)\n",
            "test_y: (10000,)\n",
            "0 loss= 3.69053664416075\n",
            "1 loss= 1.0239814753333734\n",
            "2 loss= 0.8484694286187497\n",
            "3 loss= 0.7684730100631708\n",
            "4 loss= 0.7141652611394728\n",
            "5 loss= 0.6801977543532853\n",
            "6 loss= 0.6383924385905266\n",
            "7 loss= 0.5966851238409681\n",
            "8 loss= 0.560877526452144\n",
            "9 loss= 0.5218397782742983\n",
            "accuracy= 0.8498\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVnaNGbd1PDW",
        "colab_type": "text"
      },
      "source": [
        "## 이미지 별 예측 결과 직접 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgdt1cQ_1Rql",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "38c7971c-96cd-4e30-a925-9aaa81a06cdc"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# 의류 이미지와 예측 결과 살펴보기\n",
        "plt.figure()\n",
        "check_data = 30\n",
        "# 예측 label 출력\n",
        "print(\"predicted label=\", predict_labels[check_data])\n",
        "\n",
        "image = np.reshape(test_x[check_data], [28, 28]) # 이미지 만들기\n",
        "plt.imshow(image, cmap='Greys')\n",
        "plt.show() # 이미지 출력\n"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predicted label= 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niYJi+ImCYviJgvp/mHqjeFEfkqgAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWIlmiOqYcGJ",
        "colab_type": "text"
      },
      "source": [
        "# 6. 추가 실습 - CIFAR 이미지 분류"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMrh3sVsexwx",
        "colab_type": "text"
      },
      "source": [
        "## class MLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1pkY7ULe5it",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class MLP_6:\n",
        "    def __init__(self, num_features, num_classes):\n",
        "      pass\n",
        "    \n",
        "    def train(self, train_x, train_y):\n",
        "      pass\n",
        "    \n",
        "    def predict(self, test_x):\n",
        "      pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Au-5olR9iLY1",
        "colab_type": "text"
      },
      "source": [
        "## pickle 파일 읽기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHSPoRNUiNcK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "\n",
        "def unpickle(file):\n",
        "    with open(file, 'rb') as fo:\n",
        "        dict = pickle.load(fo, encoding='bytes')\n",
        "    return dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewq9LIEKfFnN",
        "colab_type": "text"
      },
      "source": [
        "## 데이터 생성, 학습 및 평가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a18X56gzfIpO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = \"sample_data/\"\n",
        "file_train = \"cifar_train_small\"\n",
        "file_test = \"cifar_test_small\"\n",
        "input_train = unpickle(path + file_train)\n",
        "input_test = unpickle(path + file_test)\n",
        "\n",
        "train_x = input_train['data']\n",
        "train_y = input_train['labels']\n",
        "test_x = input_test['data']\n",
        "test_y = input_test['labels']\n",
        "\n",
        "print(\"train_x:\", train_x.shape) # (5000, 3072)\n",
        "print(\"train_y:\", train_y.shape) # (5000, )\n",
        "print(\"test_x:\", test_x.shape)   # (1000, 3072)\n",
        "print(\"test_y:\", test_y.shape)   # (1000, )\n",
        "\n",
        "# 모델 생성, 학습 및 평가\n",
        "# ..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pa5_A3_eDn5H",
        "colab_type": "text"
      },
      "source": [
        "## 이미지 별 예측 결과 직접 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPHwlrjaDssJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "check_data = 10\n",
        "label_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "# 예측 label 출력\n",
        "print(\"predicted label=\", label_names[predict_labels[check_data]])\n",
        "\n",
        "# 이미지 만들기\n",
        "image_r = test_x[check_data][0:1024].reshape(32,32)\n",
        "image_g = test_x[check_data][1024:2048].reshape(32,32)\n",
        "image_b = test_x[check_data][2048:].reshape(32,32)\n",
        "image = np.dstack((image_r, image_g, image_b))\n",
        "plt.figure()\n",
        "plt.imshow(image)\n",
        "plt.show() # 이미지 출력"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCdX_SVUDtxk",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}